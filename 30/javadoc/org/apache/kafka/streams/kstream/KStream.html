<!DOCTYPE HTML>
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc -->
<title>KStream (kafka 3.0.2 API)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="description" content="declaration: package: org.apache.kafka.streams.kstream, interface: KStream">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
<script type="text/javascript" src="../../../../../script-dir/jquery-3.5.1.min.js"></script>
<script type="text/javascript" src="../../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var data = {"i0":38,"i1":38,"i2":6,"i3":6,"i4":6,"i5":6,"i6":6,"i7":6,"i8":6,"i9":6,"i10":6,"i11":6,"i12":6,"i13":6,"i14":6,"i15":6,"i16":6,"i17":6,"i18":6,"i19":6,"i20":6,"i21":6,"i22":6,"i23":6,"i24":6,"i25":6,"i26":6,"i27":6,"i28":6,"i29":6,"i30":6,"i31":6,"i32":6,"i33":6,"i34":6,"i35":6,"i36":6,"i37":6,"i38":6,"i39":6,"i40":6,"i41":6,"i42":6,"i43":6,"i44":6,"i45":6,"i46":6,"i47":6,"i48":6,"i49":6,"i50":6,"i51":6,"i52":6,"i53":6,"i54":6,"i55":6,"i56":6,"i57":6,"i58":6,"i59":6,"i60":6,"i61":6,"i62":6,"i63":6,"i64":6,"i65":38,"i66":38,"i67":6,"i68":6,"i69":6,"i70":6,"i71":6,"i72":6,"i73":38,"i74":38,"i75":6,"i76":6,"i77":6,"i78":6,"i79":6,"i80":6,"i81":6,"i82":6,"i83":6,"i84":6,"i85":6,"i86":6,"i87":6,"i88":6};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],4:["t3","Abstract Methods"],32:["t6","Deprecated Methods"]};
var altColor = "alt-color";
var rowColor = "row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar.top">
<div class="skip-nav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar.top.firstrow" class="nav-list" title="Navigation">
<li><a href="../../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search">SEARCH:</label>
<input type="text" id="search" value="search" disabled="disabled">
<input type="reset" id="reset" value="reset" disabled="disabled">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip.navbar.top">
<!--   -->
</span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">org.apache.kafka.streams.kstream</a></div>
<h1 title="Interface KStream" class="title">Interface KStream&lt;K,&#8203;V&gt;</h1>
</div>
<section class="description">
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>K</code> - Type of keys</dd>
<dd><code>V</code> - Type of values</dd>
</dl>
<hr>
<pre>public interface <span class="type-name-label">KStream&lt;K,&#8203;V&gt;</span></pre>
<div class="block"><code>KStream</code> is an abstraction of a <i>record stream</i> of <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs, i.e., each record is an
 independent entity/event in the real world.
 For example a user X might buy two items I1 and I2, and thus there might be two records <code>&lt;K:I1&gt;, &lt;K:I2&gt;</code>
 in the stream.
 <p>
 A <code>KStream</code> is either <a href="../StreamsBuilder.html#stream(java.lang.String)"><code>defined from one or multiple Kafka topics</code></a> that
 are consumed message by message or the result of a <code>KStream</code> transformation.
 A <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> can also be <a href="KTable.html#toStream()"><code>converted</code></a> into a <code>KStream</code>.
 <p>
 A <code>KStream</code> can be transformed record by record, joined with another <code>KStream</code>, <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>,
 <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>, or can be aggregated into a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Kafka Streams DSL can be mixed-and-matched with Processor API (PAPI) (c.f. <a href="../Topology.html" title="class in org.apache.kafka.streams"><code>Topology</code></a>) via
 <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(...)</code></a>,
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(...)</code></a>, and
 <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(...)</code></a>.</div>
<dl class="notes">
<dt>See Also:</dt>
<dd><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>, 
<a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>, 
<a href="../StreamsBuilder.html#stream(java.lang.String)"><code>StreamsBuilder.stream(String)</code></a></dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method.summary">
<h2>Method Summary</h2>
<div class="member-summary" id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" id="t0" class="active-table-tab">All Methods</button><button role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" id="t2" class="table-tab" onclick="show(2);">Instance Methods</button><button role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" id="t3" class="table-tab" onclick="show(4);">Abstract Methods</button><button role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" id="t6" class="table-tab" onclick="show(32);">Deprecated Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<table class="summary-table" aria-labelledby="t0">
<thead>
<tr>
<th class="col-first" scope="col">Modifier and Type</th>
<th class="col-second" scope="col">Method</th>
<th class="col-last" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr class="alt-color" id="i0">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;[]</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#branch(org.apache.kafka.streams.kstream.Named,org.apache.kafka.streams.kstream.Predicate...)">branch</a></span>&#8203;(<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;...&nbsp;predicates)</code></th>
<td class="col-last">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.8.</div>
</div>
</td>
</tr>
<tr class="row-color" id="i1">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;[]</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#branch(org.apache.kafka.streams.kstream.Predicate...)">branch</a></span>&#8203;(<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;...&nbsp;predicates)</code></th>
<td class="col-last">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.8.</div>
</div>
</td>
</tr>
<tr class="alt-color" id="i2">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#filter(org.apache.kafka.streams.kstream.Predicate)">filter</a></span>&#8203;(<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> that consists of all records of this stream which satisfy the given predicate.</div>
</td>
</tr>
<tr class="row-color" id="i3">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#filter(org.apache.kafka.streams.kstream.Predicate,org.apache.kafka.streams.kstream.Named)">filter</a></span>&#8203;(<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> that consists of all records of this stream which satisfy the given predicate.</div>
</td>
</tr>
<tr class="alt-color" id="i4">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#filterNot(org.apache.kafka.streams.kstream.Predicate)">filterNot</a></span>&#8203;(<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> that consists all records of this stream which do <em>not</em> satisfy the given
 predicate.</div>
</td>
</tr>
<tr class="row-color" id="i5">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#filterNot(org.apache.kafka.streams.kstream.Predicate,org.apache.kafka.streams.kstream.Named)">filterNot</a></span>&#8203;(<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> that consists all records of this stream which do <em>not</em> satisfy the given
 predicate.</div>
</td>
</tr>
<tr class="alt-color" id="i6">
<td class="col-first"><code>&lt;KR,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)">flatMap</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).</div>
</td>
</tr>
<tr class="row-color" id="i7">
<td class="col-first"><code>&lt;KR,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Named)">flatMap</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).</div>
</td>
</tr>
<tr class="alt-color" id="i8">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)">flatMapValues</a></span>&#8203;(<a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.</div>
</td>
</tr>
<tr class="row-color" id="i9">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper,org.apache.kafka.streams.kstream.Named)">flatMapValues</a></span>&#8203;(<a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.</div>
</td>
</tr>
<tr class="alt-color" id="i10">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)">flatMapValues</a></span>&#8203;(<a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.</div>
</td>
</tr>
<tr class="row-color" id="i11">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey,org.apache.kafka.streams.kstream.Named)">flatMapValues</a></span>&#8203;(<a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.</div>
</td>
</tr>
<tr class="alt-color" id="i12">
<td class="col-first"><code>&lt;K1,&#8203;
V1&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)">flatTransform</a></span>&#8203;(<a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&gt;&nbsp;transformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).</div>
</td>
</tr>
<tr class="row-color" id="i13">
<td class="col-first"><code>&lt;K1,&#8203;
V1&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">flatTransform</a></span>&#8203;(<a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&gt;&nbsp;transformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).</div>
</td>
</tr>
<tr class="alt-color" id="i14">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)">flatTransformValues</a></span>&#8203;(<a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.</div>
</td>
</tr>
<tr class="row-color" id="i15">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">flatTransformValues</a></span>&#8203;(<a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.</div>
</td>
</tr>
<tr class="alt-color" id="i16">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)">flatTransformValues</a></span>&#8203;(<a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.</div>
</td>
</tr>
<tr class="row-color" id="i17">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">flatTransformValues</a></span>&#8203;(<a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.</div>
</td>
</tr>
<tr class="alt-color" id="i18">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)">foreach</a></span>&#8203;(<a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action)</code></th>
<td class="col-last">
<div class="block">Perform an action on each record of <code>KStream</code>.</div>
</td>
</tr>
<tr class="row-color" id="i19">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction,org.apache.kafka.streams.kstream.Named)">foreach</a></span>&#8203;(<a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Perform an action on each record of <code>KStream</code>.</div>
</td>
</tr>
<tr class="alt-color" id="i20">
<td class="col-first"><code>&lt;KR&gt;&nbsp;<a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#groupBy(org.apache.kafka.streams.kstream.KeyValueMapper)">groupBy</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;KR&gt;&nbsp;keySelector)</code></th>
<td class="col-last">
<div class="block">Group the records of this <code>KStream</code> on a new key that is selected using the provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a>
 and default serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i21">
<td class="col-first"><code>&lt;KR&gt;&nbsp;<a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#groupBy(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Grouped)">groupBy</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;KR&gt;&nbsp;keySelector,
<a href="Grouped.html" title="class in org.apache.kafka.streams.kstream">Grouped</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;grouped)</code></th>
<td class="col-last">
<div class="block">Group the records of this <code>KStream</code> on a new key that is selected using the provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a>
 and <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>Serde</code></a>s as specified by <a href="Grouped.html" title="class in org.apache.kafka.streams.kstream"><code>Grouped</code></a>.</div>
</td>
</tr>
<tr class="alt-color" id="i22">
<td class="col-first"><code><a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#groupByKey()">groupByKey</a></span>()</code></th>
<td class="col-last">
<div class="block">Group the records by their current key into a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> while preserving the original values
 and default serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i23">
<td class="col-first"><code><a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#groupByKey(org.apache.kafka.streams.kstream.Grouped)">groupByKey</a></span>&#8203;(<a href="Grouped.html" title="class in org.apache.kafka.streams.kstream">Grouped</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;grouped)</code></th>
<td class="col-last">
<div class="block">Group the records by their current key into a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> while preserving the original values
 and using the serializers as defined by <a href="Grouped.html" title="class in org.apache.kafka.streams.kstream"><code>Grouped</code></a>.</div>
</td>
</tr>
<tr class="alt-color" id="i24">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)">join</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.</div>
</td>
</tr>
<tr class="row-color" id="i25">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Named)">join</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.</div>
</td>
</tr>
<tr class="alt-color" id="i26">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">join</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.</div>
</td>
</tr>
<tr class="row-color" id="i27">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Named)">join</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.</div>
</td>
</tr>
<tr class="alt-color" id="i28">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)">join</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i29">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">join</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.</div>
</td>
</tr>
<tr class="alt-color" id="i30">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)">join</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i31">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">join</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.</div>
</td>
</tr>
<tr class="alt-color" id="i32">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)">join</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i33">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Joined)">join</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="alt-color" id="i34">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">join</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i35">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Joined)">join</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="alt-color" id="i36">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)">leftJoin</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.</div>
</td>
</tr>
<tr class="row-color" id="i37">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Named)">leftJoin</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.</div>
</td>
</tr>
<tr class="alt-color" id="i38">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">leftJoin</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.</div>
</td>
</tr>
<tr class="row-color" id="i39">
<td class="col-first"><code>&lt;GK,&#8203;
GV,&#8203;
RV&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Named)">leftJoin</a></span>&#8203;(<a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.</div>
</td>
</tr>
<tr class="alt-color" id="i40">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)">leftJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i41">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">leftJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.</div>
</td>
</tr>
<tr class="alt-color" id="i42">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)">leftJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i43">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">leftJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.</div>
</td>
</tr>
<tr class="alt-color" id="i44">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)">leftJoin</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i45">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Joined)">leftJoin</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="alt-color" id="i46">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">leftJoin</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i47">
<td class="col-first"><code>&lt;VT,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Joined)">leftJoin</a></span>&#8203;(<a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="alt-color" id="i48">
<td class="col-first"><code>&lt;KR,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)">map</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into a new record in the output stream (both key and value type can be
 altered arbitrarily).</div>
</td>
</tr>
<tr class="row-color" id="i49">
<td class="col-first"><code>&lt;KR,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Named)">map</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into a new record in the output stream (both key and value type can be
 altered arbitrarily).</div>
</td>
</tr>
<tr class="alt-color" id="i50">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)">mapValues</a></span>&#8203;(<a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.</div>
</td>
</tr>
<tr class="row-color" id="i51">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper,org.apache.kafka.streams.kstream.Named)">mapValues</a></span>&#8203;(<a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.</div>
</td>
</tr>
<tr class="alt-color" id="i52">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)">mapValues</a></span>&#8203;(<a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.</div>
</td>
</tr>
<tr class="row-color" id="i53">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey,org.apache.kafka.streams.kstream.Named)">mapValues</a></span>&#8203;(<a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.</div>
</td>
</tr>
<tr class="alt-color" id="i54">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#merge(org.apache.kafka.streams.kstream.KStream)">merge</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;stream)</code></th>
<td class="col-last">
<div class="block">Merge this stream and the given stream into one larger stream.</div>
</td>
</tr>
<tr class="row-color" id="i55">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#merge(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.Named)">merge</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;stream,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Merge this stream and the given stream into one larger stream.</div>
</td>
</tr>
<tr class="alt-color" id="i56">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)">outerJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i57">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">outerJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.</div>
</td>
</tr>
<tr class="alt-color" id="i58">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)">outerJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join with default
 serializers and deserializers.</div>
</td>
</tr>
<tr class="row-color" id="i59">
<td class="col-first"><code>&lt;VO,&#8203;
VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">outerJoin</a></span>&#8203;(<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</code></th>
<td class="col-last">
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.</div>
</td>
</tr>
<tr class="alt-color" id="i60">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#peek(org.apache.kafka.streams.kstream.ForeachAction)">peek</a></span>&#8203;(<a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action)</code></th>
<td class="col-last">
<div class="block">Perform an action on each record of <code>KStream</code>.</div>
</td>
</tr>
<tr class="row-color" id="i61">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#peek(org.apache.kafka.streams.kstream.ForeachAction,org.apache.kafka.streams.kstream.Named)">peek</a></span>&#8203;(<a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Perform an action on each record of <code>KStream</code>.</div>
</td>
</tr>
<tr class="alt-color" id="i62">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#print(org.apache.kafka.streams.kstream.Printed)">print</a></span>&#8203;(<a href="Printed.html" title="class in org.apache.kafka.streams.kstream">Printed</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;printed)</code></th>
<td class="col-last">
<div class="block">Print the records of this KStream using the options provided by <a href="Printed.html" title="class in org.apache.kafka.streams.kstream"><code>Printed</code></a>
 Note that this is mainly for debugging/testing purposes, and it will try to flush on each record print.</div>
</td>
</tr>
<tr class="row-color" id="i63">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)">process</a></span>&#8203;(<a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>&gt;&nbsp;processorSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Process all records in this stream, one record at a time, by applying a <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a> (provided by the given
 <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a>).</div>
</td>
</tr>
<tr class="alt-color" id="i64">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">process</a></span>&#8203;(<a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>&gt;&nbsp;processorSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Process all records in this stream, one record at a time, by applying a <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a> (provided by the given
 <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a>).</div>
</td>
</tr>
<tr class="row-color" id="i65">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#process(org.apache.kafka.streams.processor.ProcessorSupplier,java.lang.String...)">process</a></span>&#8203;(<a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;processorSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">Since 3.0.</div>
</div>
</td>
</tr>
<tr class="alt-color" id="i66">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#process(org.apache.kafka.streams.processor.ProcessorSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">process</a></span>&#8203;(<a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;processorSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">Since 3.0.</div>
</div>
</td>
</tr>
<tr class="row-color" id="i67">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#repartition()">repartition</a></span>()</code></th>
<td class="col-last">
<div class="block">Materialize this stream to an auto-generated repartition topic and create a new <code>KStream</code>
 from the auto-generated topic using default serializers, deserializers, and producer's <code>DefaultPartitioner</code>.</div>
</td>
</tr>
<tr class="alt-color" id="i68">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)">repartition</a></span>&#8203;(<a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream">Repartitioned</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;repartitioned)</code></th>
<td class="col-last">
<div class="block">Materialize this stream to an auto-generated repartition topic and create a new <code>KStream</code>
 from the auto-generated topic using <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>value serde</code></a>, <a href="../processor/StreamPartitioner.html" title="interface in org.apache.kafka.streams.processor"><code>StreamPartitioner</code></a>,
 number of partitions, and topic name part as defined by <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a>.</div>
</td>
</tr>
<tr class="row-color" id="i69">
<td class="col-first"><code>&lt;KR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)">selectKey</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends KR&gt;&nbsp;mapper)</code></th>
<td class="col-last">
<div class="block">Set a new key (with possibly new type) for each input record.</div>
</td>
</tr>
<tr class="alt-color" id="i70">
<td class="col-first"><code>&lt;KR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Named)">selectKey</a></span>&#8203;(<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends KR&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Set a new key (with possibly new type) for each input record.</div>
</td>
</tr>
<tr class="row-color" id="i71">
<td class="col-first"><code><a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream">BranchedKStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#split()">split</a></span>()</code></th>
<td class="col-last">
<div class="block">Split this stream into different branches.</div>
</td>
</tr>
<tr class="alt-color" id="i72">
<td class="col-first"><code><a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream">BranchedKStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#split(org.apache.kafka.streams.kstream.Named)">split</a></span>&#8203;(<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Split this stream into different branches.</div>
</td>
</tr>
<tr class="row-color" id="i73">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#through(java.lang.String)">through</a></span>&#8203;(<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic)</code></th>
<td class="col-last">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.6; use <a href="#repartition()"><code>repartition()</code></a> instead</div>
</div>
</td>
</tr>
<tr class="alt-color" id="i74">
<td class="col-first"><code><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#through(java.lang.String,org.apache.kafka.streams.kstream.Produced)">through</a></span>&#8203;(<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic,
<a href="Produced.html" title="class in org.apache.kafka.streams.kstream">Produced</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;produced)</code></th>
<td class="col-last">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.6; use <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> instead</div>
</div>
</td>
</tr>
<tr class="row-color" id="i75">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#to(java.lang.String)">to</a></span>&#8203;(<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic)</code></th>
<td class="col-last">
<div class="block">Materialize this stream to a topic using default serializers specified in the config and producer's
 <code>DefaultPartitioner</code>.</div>
</td>
</tr>
<tr class="alt-color" id="i76">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#to(java.lang.String,org.apache.kafka.streams.kstream.Produced)">to</a></span>&#8203;(<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic,
<a href="Produced.html" title="class in org.apache.kafka.streams.kstream">Produced</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;produced)</code></th>
<td class="col-last">
<div class="block">Materialize this stream to a topic using the provided <a href="Produced.html" title="class in org.apache.kafka.streams.kstream"><code>Produced</code></a> instance.</div>
</td>
</tr>
<tr class="row-color" id="i77">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#to(org.apache.kafka.streams.processor.TopicNameExtractor)">to</a></span>&#8203;(<a href="../processor/TopicNameExtractor.html" title="interface in org.apache.kafka.streams.processor">TopicNameExtractor</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;topicExtractor)</code></th>
<td class="col-last">
<div class="block">Dynamically materialize this stream to topics using default serializers specified in the config and producer's
 <code>DefaultPartitioner</code>.</div>
</td>
</tr>
<tr class="alt-color" id="i78">
<td class="col-first"><code>void</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#to(org.apache.kafka.streams.processor.TopicNameExtractor,org.apache.kafka.streams.kstream.Produced)">to</a></span>&#8203;(<a href="../processor/TopicNameExtractor.html" title="interface in org.apache.kafka.streams.processor">TopicNameExtractor</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;topicExtractor,
<a href="Produced.html" title="class in org.apache.kafka.streams.kstream">Produced</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;produced)</code></th>
<td class="col-last">
<div class="block">Dynamically materialize this stream to topics using the provided <a href="Produced.html" title="class in org.apache.kafka.streams.kstream"><code>Produced</code></a> instance.</div>
</td>
</tr>
<tr class="row-color" id="i79">
<td class="col-first"><code><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#toTable()">toTable</a></span>()</code></th>
<td class="col-last">
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.</div>
</td>
</tr>
<tr class="alt-color" id="i80">
<td class="col-first"><code><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#toTable(org.apache.kafka.streams.kstream.Materialized)">toTable</a></span>&#8203;(<a href="Materialized.html" title="class in org.apache.kafka.streams.kstream">Materialized</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../state/KeyValueStore.html" title="interface in org.apache.kafka.streams.state">KeyValueStore</a>&lt;org.apache.kafka.common.utils.Bytes,&#8203;byte[]&gt;&gt;&nbsp;materialized)</code></th>
<td class="col-last">
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.</div>
</td>
</tr>
<tr class="row-color" id="i81">
<td class="col-first"><code><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#toTable(org.apache.kafka.streams.kstream.Named)">toTable</a></span>&#8203;(<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</code></th>
<td class="col-last">
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.</div>
</td>
</tr>
<tr class="alt-color" id="i82">
<td class="col-first"><code><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#toTable(org.apache.kafka.streams.kstream.Named,org.apache.kafka.streams.kstream.Materialized)">toTable</a></span>&#8203;(<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="Materialized.html" title="class in org.apache.kafka.streams.kstream">Materialized</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../state/KeyValueStore.html" title="interface in org.apache.kafka.streams.state">KeyValueStore</a>&lt;org.apache.kafka.common.utils.Bytes,&#8203;byte[]&gt;&gt;&nbsp;materialized)</code></th>
<td class="col-last">
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.</div>
</td>
</tr>
<tr class="row-color" id="i83">
<td class="col-first"><code>&lt;K1,&#8203;
V1&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)">transform</a></span>&#8203;(<a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&nbsp;transformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into zero or one record in the output stream (both key and value type
 can be altered arbitrarily).</div>
</td>
</tr>
<tr class="alt-color" id="i84">
<td class="col-first"><code>&lt;K1,&#8203;
V1&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">transform</a></span>&#8203;(<a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&nbsp;transformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform each record of the input stream into zero or one record in the output stream (both key and value type
 can be altered arbitrarily).</div>
</td>
</tr>
<tr class="row-color" id="i85">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)">transformValues</a></span>&#8203;(<a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.</div>
</td>
</tr>
<tr class="alt-color" id="i86">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">transformValues</a></span>&#8203;(<a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.</div>
</td>
</tr>
<tr class="row-color" id="i87">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)">transformValues</a></span>&#8203;(<a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.</div>
</td>
</tr>
<tr class="alt-color" id="i88">
<td class="col-first"><code>&lt;VR&gt;&nbsp;<a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</code></td>
<th class="col-second" scope="row"><code><span class="member-name-link"><a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">transformValues</a></span>&#8203;(<a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</code></th>
<td class="col-last">
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method.detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="filter(org.apache.kafka.streams.kstream.Predicate)">
<h3>filter</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">filter</span>&#8203;(<span class="parameters"><a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate)</span></div>
<div class="block">Create a new <code>KStream</code> that consists of all records of this stream which satisfy the given predicate.
 All records that do not satisfy the predicate are dropped.
 This is a stateless record-by-record operation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>predicate</code> - a filter <a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream"><code>Predicate</code></a> that is applied to each record</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains only those records that satisfy the given predicate</dd>
<dt>See Also:</dt>
<dd><a href="#filterNot(org.apache.kafka.streams.kstream.Predicate)"><code>filterNot(Predicate)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filter(org.apache.kafka.streams.kstream.Predicate,org.apache.kafka.streams.kstream.Named)">
<h3>filter</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">filter</span>&#8203;(<span class="parameters"><a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Create a new <code>KStream</code> that consists of all records of this stream which satisfy the given predicate.
 All records that do not satisfy the predicate are dropped.
 This is a stateless record-by-record operation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>predicate</code> - a filter <a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream"><code>Predicate</code></a> that is applied to each record</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains only those records that satisfy the given predicate</dd>
<dt>See Also:</dt>
<dd><a href="#filterNot(org.apache.kafka.streams.kstream.Predicate)"><code>filterNot(Predicate)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filterNot(org.apache.kafka.streams.kstream.Predicate)">
<h3>filterNot</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">filterNot</span>&#8203;(<span class="parameters"><a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate)</span></div>
<div class="block">Create a new <code>KStream</code> that consists all records of this stream which do <em>not</em> satisfy the given
 predicate.
 All records that <em>do</em> satisfy the predicate are dropped.
 This is a stateless record-by-record operation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>predicate</code> - a filter <a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream"><code>Predicate</code></a> that is applied to each record</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains only those records that do <em>not</em> satisfy the given predicate</dd>
<dt>See Also:</dt>
<dd><a href="#filter(org.apache.kafka.streams.kstream.Predicate)"><code>filter(Predicate)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filterNot(org.apache.kafka.streams.kstream.Predicate,org.apache.kafka.streams.kstream.Named)">
<h3>filterNot</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">filterNot</span>&#8203;(<span class="parameters"><a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;predicate,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Create a new <code>KStream</code> that consists all records of this stream which do <em>not</em> satisfy the given
 predicate.
 All records that <em>do</em> satisfy the predicate are dropped.
 This is a stateless record-by-record operation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>predicate</code> - a filter <a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream"><code>Predicate</code></a> that is applied to each record</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains only those records that do <em>not</em> satisfy the given predicate</dd>
<dt>See Also:</dt>
<dd><a href="#filter(org.apache.kafka.streams.kstream.Predicate)"><code>filter(Predicate)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)">
<h3>selectKey</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">selectKey</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends KR&gt;&nbsp;mapper)</span></div>
<div class="block">Set a new key (with possibly new type) for each input record.
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> is applied to each input record and computes a new key for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K':V&gt;</code>.
 This is a stateless record-by-record operation.
 <p>
 For example, you can use this transformation to set a key for a key-less input record <code>&lt;null,V&gt;</code> by
 extracting a key from the value within your <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a>. The example below computes the new key as the
 length of the value string.
 <pre><code>
 KStream&lt;Byte[], String&gt; keyLessStream = builder.stream("key-less-topic");
 KStream&lt;Integer, String&gt; keyedStream = keyLessStream.selectKey(new KeyValueMapper&lt;Byte[], String, Integer&gt; {
     Integer apply(Byte[] key, String value) {
         return value.length();
     }
 });
 </code></pre>
 Setting a new key might result in an internal data redistribution if a key based operator (like an aggregation or
 join) is applied to the result <code>KStream</code>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the new key type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes a new key for each record</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with new key (possibly of different type) and unmodified value</dd>
<dt>See Also:</dt>
<dd><a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="selectKey(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Named)">
<h3>selectKey</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">selectKey</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends KR&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Set a new key (with possibly new type) for each input record.
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> is applied to each input record and computes a new key for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K':V&gt;</code>.
 This is a stateless record-by-record operation.
 <p>
 For example, you can use this transformation to set a key for a key-less input record <code>&lt;null,V&gt;</code> by
 extracting a key from the value within your <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a>. The example below computes the new key as the
 length of the value string.
 <pre><code>
 KStream&lt;Byte[], String&gt; keyLessStream = builder.stream("key-less-topic");
 KStream&lt;Integer, String&gt; keyedStream = keyLessStream.selectKey(new KeyValueMapper&lt;Byte[], String, Integer&gt; {
     Integer apply(Byte[] key, String value) {
         return value.length();
     }
 });
 </code></pre>
 Setting a new key might result in an internal data redistribution if a key based operator (like an aggregation or
 join) is applied to the result <code>KStream</code>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the new key type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes a new key for each record</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with new key (possibly of different type) and unmodified value</dd>
<dt>See Also:</dt>
<dd><a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="map(org.apache.kafka.streams.kstream.KeyValueMapper)">
<h3>map</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</span>&nbsp;<span class="member-name">map</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&nbsp;mapper)</span></div>
<div class="block">Transform each record of the input stream into a new record in the output stream (both key and value type can be
 altered arbitrarily).
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> is applied to each input record and computes a new output record.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K':V'&gt;</code>.
 This is a stateless record-by-record operation (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a> for
 stateful record transformation).
 <p>
 The example below normalizes the String key to upper-case letters and counts the number of token of the value string.
 <pre><code>
 KStream&lt;String, String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.map(new KeyValueMapper&lt;String, String, KeyValue&lt;String, Integer&gt;&gt; {
     KeyValue&lt;String, Integer&gt; apply(String key, String value) {
         return new KeyValue&lt;&gt;(key.toUpperCase(), value.split(" ").length);
     }
 });
 </code></pre>
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> must return a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> type and must not return <code>null</code>.
 <p>
 Mapping records might result in an internal data redistribution if a key based operator (like an aggregation or
 join) is applied to the result <code>KStream</code>. (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the key type of the result stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes a new output record</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with new key and value (possibly both of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="map(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Named)">
<h3>map</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</span>&nbsp;<span class="member-name">map</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Transform each record of the input stream into a new record in the output stream (both key and value type can be
 altered arbitrarily).
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> is applied to each input record and computes a new output record.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K':V'&gt;</code>.
 This is a stateless record-by-record operation (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a> for
 stateful record transformation).
 <p>
 The example below normalizes the String key to upper-case letters and counts the number of token of the value string.
 <pre><code>
 KStream&lt;String, String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.map(new KeyValueMapper&lt;String, String, KeyValue&lt;String, Integer&gt;&gt; {
     KeyValue&lt;String, Integer&gt; apply(String key, String value) {
         return new KeyValue&lt;&gt;(key.toUpperCase(), value.split(" ").length);
     }
 });
 </code></pre>
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> must return a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> type and must not return <code>null</code>.
 <p>
 Mapping records might result in an internal data redistribution if a key based operator (like an aggregation or
 join) is applied to the result <code>KStream</code>. (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the key type of the result stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes a new output record</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with new key and value (possibly both of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapValues(org.apache.kafka.streams.kstream.ValueMapper)">
<h3>mapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">mapValues</span>&#8203;(<span class="parameters"><a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper)</span></div>
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.
 The provided <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> is applied to each input record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 This is a stateless record-by-record operation (cf.
 <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a> for stateful value transformation).
 <p>
 The example below counts the number of token of the value string.
 <pre><code>
 KStream&lt;String, String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.mapValues(new ValueMapper&lt;String, Integer&gt; {
     Integer apply(String value) {
         return value.split(" ").length;
     }
 });
 </code></pre>
 Setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> that computes a new output value</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapValues(org.apache.kafka.streams.kstream.ValueMapper,org.apache.kafka.streams.kstream.Named)">
<h3>mapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">mapValues</span>&#8203;(<span class="parameters"><a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.
 The provided <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> is applied to each input record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 This is a stateless record-by-record operation (cf.
 <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a> for stateful value transformation).
 <p>
 The example below counts the number of token of the value string.
 <pre><code>
 KStream&lt;String, String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.mapValues(new ValueMapper&lt;String, Integer&gt; {
     Integer apply(String value) {
         return value.split(" ").length;
     }
 });
 </code></pre>
 Setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> that computes a new output value</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)">
<h3>mapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">mapValues</span>&#8203;(<span class="parameters"><a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper)</span></div>
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.
 The provided <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> is applied to each input record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 This is a stateless record-by-record operation (cf.
 <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a> for stateful value transformation).
 <p>
 The example below counts the number of tokens of key and value strings.
 <pre><code>
 KStream&lt;String, String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.mapValues(new ValueMapperWithKey&lt;String, String, Integer&gt; {
     Integer apply(String readOnlyKey, String value) {
         return readOnlyKey.split(" ").length + value.split(" ").length;
     }
 });
 </code></pre>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> that computes a new output value</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey,org.apache.kafka.streams.kstream.Named)">
<h3>mapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">mapValues</span>&#8203;(<span class="parameters"><a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Transform the value of each input record into a new value (with possible new type) of the output record.
 The provided <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> is applied to each input record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 This is a stateless record-by-record operation (cf.
 <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a> for stateful value transformation).
 <p>
 The example below counts the number of tokens of key and value strings.
 <pre><code>
 KStream&lt;String, String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.mapValues(new ValueMapperWithKey&lt;String, String, Integer&gt; {
     Integer apply(String readOnlyKey, String value) {
         return readOnlyKey.split(" ").length + value.split(" ").length;
     }
 });
 </code></pre>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> that computes a new output value</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)">
<h3>flatMap</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatMap</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&gt;&nbsp;mapper)</span></div>
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> is applied to each input record and computes zero or more output records.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K':V'&gt;, &lt;K'':V''&gt;, ...</code>.
 This is a stateless record-by-record operation (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a> for
 stateful record transformation).
 <p>
 The example below splits input records <code>&lt;null:String&gt;</code> containing sentences as values into their words
 and emit a record <code>&lt;word:1&gt;</code> for each word.
 <pre><code>
 KStream&lt;byte[], String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.flatMap(
     new KeyValueMapper&lt;byte[], String, Iterable&lt;KeyValue&lt;String, Integer&gt;&gt;&gt; {
         Iterable&lt;KeyValue&lt;String, Integer&gt;&gt; apply(byte[] key, String value) {
             String[] tokens = value.split(" ");
             List&lt;KeyValue&lt;String, Integer&gt;&gt; result = new ArrayList&lt;&gt;(tokens.length);

             for(String token : tokens) {
                 result.add(new KeyValue&lt;&gt;(token, 1));
             }

             return result;
         }
     });
 </code></pre>
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type)
 and the return value must not be <code>null</code>.
 <p>
 Flat-mapping records might result in an internal data redistribution if a key based operator (like an aggregation
 or join) is applied to the result <code>KStream</code>. (cf. <a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the key type of the result stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes the new output records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with new key and value (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMap(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Named)">
<h3>flatMap</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;KR,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatMap</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends <a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;? extends KR,&#8203;? extends VR&gt;&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> is applied to each input record and computes zero or more output records.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K':V'&gt;, &lt;K'':V''&gt;, ...</code>.
 This is a stateless record-by-record operation (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a> for
 stateful record transformation).
 <p>
 The example below splits input records <code>&lt;null:String&gt;</code> containing sentences as values into their words
 and emit a record <code>&lt;word:1&gt;</code> for each word.
 <pre><code>
 KStream&lt;byte[], String&gt; inputStream = builder.stream("topic");
 KStream&lt;String, Integer&gt; outputStream = inputStream.flatMap(
     new KeyValueMapper&lt;byte[], String, Iterable&lt;KeyValue&lt;String, Integer&gt;&gt;&gt; {
         Iterable&lt;KeyValue&lt;String, Integer&gt;&gt; apply(byte[] key, String value) {
             String[] tokens = value.split(" ");
             List&lt;KeyValue&lt;String, Integer&gt;&gt; result = new ArrayList&lt;&gt;(tokens.length);

             for(String token : tokens) {
                 result.add(new KeyValue&lt;&gt;(token, 1));
             }

             return result;
         }
     });
 </code></pre>
 The provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type)
 and the return value must not be <code>null</code>.
 <p>
 Flat-mapping records might result in an internal data redistribution if a key based operator (like an aggregation
 or join) is applied to the result <code>KStream</code>. (cf. <a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the key type of the result stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes the new output records</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with new key and value (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>flatMapValues(ValueMapper)</code></a>, 
<a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMapValues(org.apache.kafka.streams.kstream.ValueMapper)">
<h3>flatMapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatMapValues</span>&#8203;(<span class="parameters"><a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper)</span></div>
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.
 Transform the value of each input record into zero or more records with the same (unmodified) key in the output
 stream (value type can be altered arbitrarily).
 The provided <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> is applied to each input record and computes zero or more output values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 This is a stateless record-by-record operation (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>
 for stateful value transformation).
 <p>
 The example below splits input records <code>&lt;null:String&gt;</code> containing sentences as values into their words.
 <pre><code>
 KStream&lt;byte[], String&gt; inputStream = builder.stream("topic");
 KStream&lt;byte[], String&gt; outputStream = inputStream.flatMapValues(new ValueMapper&lt;String, Iterable&lt;String&gt;&gt; {
     Iterable&lt;String&gt; apply(String value) {
         return Arrays.asList(value.split(" "));
     }
 });
 </code></pre>
 The provided <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type)
 and the return value must not be <code>null</code>.
 <p>
 Splitting a record into multiple records with the same key preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> the computes the new output values</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified keys and new values of different type</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMapValues(org.apache.kafka.streams.kstream.ValueMapper,org.apache.kafka.streams.kstream.Named)">
<h3>flatMapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatMapValues</span>&#8203;(<span class="parameters"><a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream">ValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.
 Transform the value of each input record into zero or more records with the same (unmodified) key in the output
 stream (value type can be altered arbitrarily).
 The provided <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> is applied to each input record and computes zero or more output values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 This is a stateless record-by-record operation (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>
 for stateful value transformation).
 <p>
 The example below splits input records <code>&lt;null:String&gt;</code> containing sentences as values into their words.
 <pre><code>
 KStream&lt;byte[], String&gt; inputStream = builder.stream("topic");
 KStream&lt;byte[], String&gt; outputStream = inputStream.flatMapValues(new ValueMapper&lt;String, Iterable&lt;String&gt;&gt; {
     Iterable&lt;String&gt; apply(String value) {
         return Arrays.asList(value.split(" "));
     }
 });
 </code></pre>
 The provided <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type)
 and the return value must not be <code>null</code>.
 <p>
 Splitting a record into multiple records with the same key preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapper</code></a> the computes the new output values</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified keys and new values of different type</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)">
<h3>flatMapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatMapValues</span>&#8203;(<span class="parameters"><a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper)</span></div>
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.
 Transform the value of each input record into zero or more records with the same (unmodified) key in the output
 stream (value type can be altered arbitrarily).
 The provided <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> is applied to each input record and computes zero or more output values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 This is a stateless record-by-record operation (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>
 for stateful value transformation).
 <p>
 The example below splits input records <code>&lt;Integer:String&gt;</code>, with key=1, containing sentences as values
 into their words.
 <pre><code>
 KStream&lt;Integer, String&gt; inputStream = builder.stream("topic");
 KStream&lt;Integer, String&gt; outputStream = inputStream.flatMapValues(new ValueMapper&lt;Integer, String, Iterable&lt;String&gt;&gt; {
     Iterable&lt;Integer, String&gt; apply(Integer readOnlyKey, String value) {
         if(readOnlyKey == 1) {
             return Arrays.asList(value.split(" "));
         } else {
             return Arrays.asList(value);
         }
     }
 });
 </code></pre>
 The provided <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type)
 and the return value must not be <code>null</code>.
 <p>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, splitting a record into multiple records with the same key preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> the computes the new output values</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified keys and new values of different type</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey,org.apache.kafka.streams.kstream.Named)">
<h3>flatMapValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatMapValues</span>&#8203;(<span class="parameters"><a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueMapperWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;? extends VR&gt;&gt;&nbsp;mapper,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Create a new <code>KStream</code> by transforming the value of each record in this stream into zero or more values
 with the same key in the new stream.
 Transform the value of each input record into zero or more records with the same (unmodified) key in the output
 stream (value type can be altered arbitrarily).
 The provided <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> is applied to each input record and computes zero or more output values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 This is a stateless record-by-record operation (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>
 for stateful value transformation).
 <p>
 The example below splits input records <code>&lt;Integer:String&gt;</code>, with key=1, containing sentences as values
 into their words.
 <pre><code>
 KStream&lt;Integer, String&gt; inputStream = builder.stream("topic");
 KStream&lt;Integer, String&gt; outputStream = inputStream.flatMapValues(new ValueMapper&lt;Integer, String, Iterable&lt;String&gt;&gt; {
     Iterable&lt;Integer, String&gt; apply(Integer readOnlyKey, String value) {
         if(readOnlyKey == 1) {
             return Arrays.asList(value.split(" "));
         } else {
             return Arrays.asList(value);
         }
     }
 });
 </code></pre>
 The provided <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type)
 and the return value must not be <code>null</code>.
 <p>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, splitting a record into multiple records with the same key preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>mapper</code> - a <a href="ValueMapperWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueMapperWithKey</code></a> the computes the new output values</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified keys and new values of different type</dd>
<dt>See Also:</dt>
<dd><a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>, 
<a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>flatTransformValues(ValueTransformerWithKeySupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="print(org.apache.kafka.streams.kstream.Printed)">
<h3>print</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">print</span>&#8203;(<span class="parameters"><a href="Printed.html" title="class in org.apache.kafka.streams.kstream">Printed</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;printed)</span></div>
<div class="block">Print the records of this KStream using the options provided by <a href="Printed.html" title="class in org.apache.kafka.streams.kstream"><code>Printed</code></a>
 Note that this is mainly for debugging/testing purposes, and it will try to flush on each record print.
 It <em>SHOULD NOT</em> be used for production usage if performance requirements are concerned.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>printed</code> - options for printing</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="foreach(org.apache.kafka.streams.kstream.ForeachAction)">
<h3>foreach</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">foreach</span>&#8203;(<span class="parameters"><a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action)</span></div>
<div class="block">Perform an action on each record of <code>KStream</code>.
 This is a stateless record-by-record operation (cf. <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a>).
 Note that this is a terminal operation that returns void.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>action</code> - an action to perform on each record</dd>
<dt>See Also:</dt>
<dd><a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="foreach(org.apache.kafka.streams.kstream.ForeachAction,org.apache.kafka.streams.kstream.Named)">
<h3>foreach</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">foreach</span>&#8203;(<span class="parameters"><a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Perform an action on each record of <code>KStream</code>.
 This is a stateless record-by-record operation (cf. <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a>).
 Note that this is a terminal operation that returns void.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>action</code> - an action to perform on each record</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>See Also:</dt>
<dd><a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="peek(org.apache.kafka.streams.kstream.ForeachAction)">
<h3>peek</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">peek</span>&#8203;(<span class="parameters"><a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action)</span></div>
<div class="block">Perform an action on each record of <code>KStream</code>.
 This is a stateless record-by-record operation (cf. <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a>).
 <p>
 Peek is a non-terminal operation that triggers a side effect (such as logging or statistics collection)
 and returns an unchanged stream.
 <p>
 Note that since this operation is stateless, it may execute multiple times for a single record in failure cases.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>action</code> - an action to perform on each record</dd>
<dt>Returns:</dt>
<dd>itself</dd>
<dt>See Also:</dt>
<dd><a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="peek(org.apache.kafka.streams.kstream.ForeachAction,org.apache.kafka.streams.kstream.Named)">
<h3>peek</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">peek</span>&#8203;(<span class="parameters"><a href="ForeachAction.html" title="interface in org.apache.kafka.streams.kstream">ForeachAction</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;action,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Perform an action on each record of <code>KStream</code>.
 This is a stateless record-by-record operation (cf. <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a>).
 <p>
 Peek is a non-terminal operation that triggers a side effect (such as logging or statistics collection)
 and returns an unchanged stream.
 <p>
 Note that since this operation is stateless, it may execute multiple times for a single record in failure cases.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>action</code> - an action to perform on each record</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>itself</dd>
<dt>See Also:</dt>
<dd><a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="branch(org.apache.kafka.streams.kstream.Predicate...)">
<h3>branch</h3>
<div class="member-signature"><span class="annotations"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Deprecated.html" title="class or interface in java.lang" class="external-link">@Deprecated</a>
</span><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;[]</span>&nbsp;<span class="member-name">branch</span>&#8203;(<span class="parameters"><a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;...&nbsp;predicates)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.8. Use <a href="#split()"><code>split()</code></a> instead.</div>
</div>
<div class="block">Creates an array of <code>KStream</code> from this stream by branching the records in the original stream based on
 the supplied predicates.
 Each record is evaluated against the supplied predicates, and predicates are evaluated in order.
 Each stream in the result array corresponds position-wise (index) to the predicate in the supplied predicates.
 The branching happens on first-match: A record in the original stream is assigned to the corresponding result
 stream for the first predicate that evaluates to true, and is assigned to this stream only.
 A record will be dropped if none of the predicates evaluate to true.
 This is a stateless record-by-record operation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>predicates</code> - the ordered list of <a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream"><code>Predicate</code></a> instances</dd>
<dt>Returns:</dt>
<dd>multiple distinct substreams of this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="branch(org.apache.kafka.streams.kstream.Named,org.apache.kafka.streams.kstream.Predicate...)">
<h3>branch</h3>
<div class="member-signature"><span class="annotations"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Deprecated.html" title="class or interface in java.lang" class="external-link">@Deprecated</a>
</span><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;[]</span>&nbsp;<span class="member-name">branch</span>&#8203;(<span class="parameters"><a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream">Predicate</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;...&nbsp;predicates)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.8. Use <a href="#split(org.apache.kafka.streams.kstream.Named)"><code>split(Named)</code></a> instead.</div>
</div>
<div class="block">Creates an array of <code>KStream</code> from this stream by branching the records in the original stream based on
 the supplied predicates.
 Each record is evaluated against the supplied predicates, and predicates are evaluated in order.
 Each stream in the result array corresponds position-wise (index) to the predicate in the supplied predicates.
 The branching happens on first-match: A record in the original stream is assigned to the corresponding result
 stream for the first predicate that evaluates to true, and is assigned to this stream only.
 A record will be dropped if none of the predicates evaluate to true.
 This is a stateless record-by-record operation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>predicates</code> - the ordered list of <a href="Predicate.html" title="interface in org.apache.kafka.streams.kstream"><code>Predicate</code></a> instances</dd>
<dt>Returns:</dt>
<dd>multiple distinct substreams of this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="split()">
<h3>split</h3>
<div class="member-signature"><span class="return-type"><a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream">BranchedKStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">split</span>()</div>
<div class="block">Split this stream into different branches. The returned <a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a> instance can be used for routing
 the records to different branches depending on evaluation against the supplied predicates.
 <p>
     Note: Stream branching is a stateless record-by-record operation.
     Please check <a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a> for detailed description and usage example</div>
<dl class="notes">
<dt>Returns:</dt>
<dd><a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a> that provides methods for routing the records to different branches.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="split(org.apache.kafka.streams.kstream.Named)">
<h3>split</h3>
<div class="member-signature"><span class="return-type"><a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream">BranchedKStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">split</span>&#8203;(<span class="parameters"><a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Split this stream into different branches. The returned <a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a> instance can be used for routing
 the records to different branches depending on evaluation against the supplied predicates.
 <p>
     Note: Stream branching is a stateless record-by-record operation.
     Please check <a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a> for detailed description and usage example</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology and also to set the name prefix
               for the resulting branches (see <a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a>)</dd>
<dt>Returns:</dt>
<dd><a href="BranchedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>BranchedKStream</code></a> that provides methods for routing the records to different branches.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="merge(org.apache.kafka.streams.kstream.KStream)">
<h3>merge</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">merge</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;stream)</span></div>
<div class="block">Merge this stream and the given stream into one larger stream.
 <p>
 There is no ordering guarantee between records from this <code>KStream</code> and records from
 the provided <code>KStream</code> in the merged stream.
 Relative order is preserved within each input stream though (ie, records within one input
 stream are processed in order).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>stream</code> - a stream which is to be merged into this stream</dd>
<dt>Returns:</dt>
<dd>a merged stream containing all records from this and the provided <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="merge(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.Named)">
<h3>merge</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">merge</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;stream,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Merge this stream and the given stream into one larger stream.
 <p>
 There is no ordering guarantee between records from this <code>KStream</code> and records from
 the provided <code>KStream</code> in the merged stream.
 Relative order is preserved within each input stream though (ie, records within one input
 stream are processed in order).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>stream</code> - a stream which is to be merged into this stream</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a merged stream containing all records from this and the provided <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="through(java.lang.String)">
<h3>through</h3>
<div class="member-signature"><span class="annotations"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Deprecated.html" title="class or interface in java.lang" class="external-link">@Deprecated</a>
</span><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">through</span>&#8203;(<span class="parameters"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.6; use <a href="#repartition()"><code>repartition()</code></a> instead</div>
</div>
<div class="block">Materialize this stream to a topic and creates a new <code>KStream</code> from the topic using default serializers,
 deserializers, and producer's <code>DefaultPartitioner</code>.
 The specified topic should be manually created before it is used (i.e., before the Kafka Streams application is
 started).
 <p>
 This is similar to calling <a href="#to(java.lang.String)"><code>#to(someTopicName)</code></a> and
 <a href="../StreamsBuilder.html#stream(java.lang.String)"><code>StreamsBuilder#stream(someTopicName)</code></a>.
 Note that <code>through()</code> uses a hard coded <a href="../processor/FailOnInvalidTimestamp.html" title="class in org.apache.kafka.streams.processor"><code>timestamp extractor</code></a> and does not allow to customize it, to ensure correct timestamp propagation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>topic</code> - the topic name</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains the exact same (and potentially repartitioned) records as this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="through(java.lang.String,org.apache.kafka.streams.kstream.Produced)">
<h3>through</h3>
<div class="member-signature"><span class="annotations"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Deprecated.html" title="class or interface in java.lang" class="external-link">@Deprecated</a>
</span><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">through</span>&#8203;(<span class="parameters"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic,
<a href="Produced.html" title="class in org.apache.kafka.streams.kstream">Produced</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;produced)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">since 2.6; use <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> instead</div>
</div>
<div class="block">Materialize this stream to a topic and creates a new <code>KStream</code> from the topic using the
 <a href="Produced.html" title="class in org.apache.kafka.streams.kstream"><code>Produced</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>value serde</code></a>,
 and <a href="../processor/StreamPartitioner.html" title="interface in org.apache.kafka.streams.processor"><code>StreamPartitioner</code></a>.
 The specified topic should be manually created before it is used (i.e., before the Kafka Streams application is
 started).
 <p>
 This is similar to calling <a href="#to(java.lang.String,org.apache.kafka.streams.kstream.Produced)"><code>to(someTopic, Produced.with(keySerde, valueSerde)</code></a>
 and <a href="../StreamsBuilder.html#stream(java.lang.String,org.apache.kafka.streams.kstream.Consumed)"><code>StreamsBuilder#stream(someTopicName, Consumed.with(keySerde, valueSerde))</code></a>.
 Note that <code>through()</code> uses a hard coded <a href="../processor/FailOnInvalidTimestamp.html" title="class in org.apache.kafka.streams.processor"><code>timestamp extractor</code></a> and does not allow to customize it, to ensure correct timestamp propagation.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>topic</code> - the topic name</dd>
<dd><code>produced</code> - the options to use when producing to the topic</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains the exact same (and potentially repartitioned) records as this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition()">
<h3>repartition</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">repartition</span>()</div>
<div class="block">Materialize this stream to an auto-generated repartition topic and create a new <code>KStream</code>
 from the auto-generated topic using default serializers, deserializers, and producer's <code>DefaultPartitioner</code>.
 The number of partitions is determined based on the upstream topics partition numbers.
 <p>
 The created topic is considered as an internal topic and is meant to be used only by the current Kafka Streams instance.
 Similar to auto-repartitioning, the topic will be created with infinite retention time and data will be automatically purged by Kafka Streams.
 The topic will be named as "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd><code>KStream</code> that contains the exact same repartitioned records as this <code>KStream</code>.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition(org.apache.kafka.streams.kstream.Repartitioned)">
<h3>repartition</h3>
<div class="member-signature"><span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">repartition</span>&#8203;(<span class="parameters"><a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream">Repartitioned</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;repartitioned)</span></div>
<div class="block">Materialize this stream to an auto-generated repartition topic and create a new <code>KStream</code>
 from the auto-generated topic using <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>value serde</code></a>, <a href="../processor/StreamPartitioner.html" title="interface in org.apache.kafka.streams.processor"><code>StreamPartitioner</code></a>,
 number of partitions, and topic name part as defined by <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a>.
 <p>
 The created topic is considered as an internal topic and is meant to be used only by the current Kafka Streams instance.
 Similar to auto-repartitioning, the topic will be created with infinite retention time and data will be automatically purged by Kafka Streams.
 The topic will be named as "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is either provided via <a href="Repartitioned.html#as(java.lang.String)"><code>Repartitioned.as(String)</code></a> or an internally
 generated name, and "-repartition" is a fixed suffix.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>repartitioned</code> - the <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> instance used to specify <a href="../../common/serialization/Serdes.html" title="class in org.apache.kafka.common.serialization"><code>Serdes</code></a>,
                      <a href="../processor/StreamPartitioner.html" title="interface in org.apache.kafka.streams.processor"><code>StreamPartitioner</code></a> which determines how records are distributed among partitions of the topic,
                      part of the topic name, and number of partitions for a repartition topic.</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains the exact same repartitioned records as this <code>KStream</code>.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="to(java.lang.String)">
<h3>to</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">to</span>&#8203;(<span class="parameters"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic)</span></div>
<div class="block">Materialize this stream to a topic using default serializers specified in the config and producer's
 <code>DefaultPartitioner</code>.
 The specified topic should be manually created before it is used (i.e., before the Kafka Streams application is
 started).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>topic</code> - the topic name</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="to(java.lang.String,org.apache.kafka.streams.kstream.Produced)">
<h3>to</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">to</span>&#8203;(<span class="parameters"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;topic,
<a href="Produced.html" title="class in org.apache.kafka.streams.kstream">Produced</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;produced)</span></div>
<div class="block">Materialize this stream to a topic using the provided <a href="Produced.html" title="class in org.apache.kafka.streams.kstream"><code>Produced</code></a> instance.
 The specified topic should be manually created before it is used (i.e., before the Kafka Streams application is
 started).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>topic</code> - the topic name</dd>
<dd><code>produced</code> - the options to use when producing to the topic</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="to(org.apache.kafka.streams.processor.TopicNameExtractor)">
<h3>to</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">to</span>&#8203;(<span class="parameters"><a href="../processor/TopicNameExtractor.html" title="interface in org.apache.kafka.streams.processor">TopicNameExtractor</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;topicExtractor)</span></div>
<div class="block">Dynamically materialize this stream to topics using default serializers specified in the config and producer's
 <code>DefaultPartitioner</code>.
 The topic names for each record to send to is dynamically determined based on the <a href="../processor/TopicNameExtractor.html" title="interface in org.apache.kafka.streams.processor"><code>TopicNameExtractor</code></a>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>topicExtractor</code> - the extractor to determine the name of the Kafka topic to write to for each record</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="to(org.apache.kafka.streams.processor.TopicNameExtractor,org.apache.kafka.streams.kstream.Produced)">
<h3>to</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">to</span>&#8203;(<span class="parameters"><a href="../processor/TopicNameExtractor.html" title="interface in org.apache.kafka.streams.processor">TopicNameExtractor</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;topicExtractor,
<a href="Produced.html" title="class in org.apache.kafka.streams.kstream">Produced</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;produced)</span></div>
<div class="block">Dynamically materialize this stream to topics using the provided <a href="Produced.html" title="class in org.apache.kafka.streams.kstream"><code>Produced</code></a> instance.
 The topic names for each record to send to is dynamically determined based on the <a href="../processor/TopicNameExtractor.html" title="interface in org.apache.kafka.streams.processor"><code>TopicNameExtractor</code></a>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>topicExtractor</code> - the extractor to determine the name of the Kafka topic to write to for each record</dd>
<dd><code>produced</code> - the options to use when producing to the topic</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toTable()">
<h3>toTable</h3>
<div class="member-signature"><span class="return-type"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">toTable</span>()</div>
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 <p>
 If a key changing operator was used before this operation (e.g., <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>,
 <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a> or
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>) an internal repartitioning topic will be created in Kafka.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 For this case, all data of this stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the resulting <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> is partitioned
 correctly on its key.
 Note that you cannot enable <a href="../StreamsConfig.html#TOPOLOGY_OPTIMIZATION_CONFIG"><code>StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG</code></a> config for this case, because
 repartition topics are considered transient and don't allow to recover the result <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> in cause of
 a failure; hence, a dedicated changelog topic is required to guarantee fault-tolerance.
 <p>
 Note that this is a logical operation and only changes the "interpretation" of the stream, i.e., each record of
 it was a "fact/event" and is re-interpreted as update now (cf. <a href="KStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KStream</code></a> vs <code>KTable</code>).</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> that contains the same records as this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toTable(org.apache.kafka.streams.kstream.Named)">
<h3>toTable</h3>
<div class="member-signature"><span class="return-type"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">toTable</span>&#8203;(<span class="parameters"><a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 <p>
 If a key changing operator was used before this operation (e.g., <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>,
 <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a> or
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>) an internal repartitioning topic will be created in Kafka.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 For this case, all data of this stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the resulting <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> is partitioned
 correctly on its key.
 Note that you cannot enable <a href="../StreamsConfig.html#TOPOLOGY_OPTIMIZATION_CONFIG"><code>StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG</code></a> config for this case, because
 repartition topics are considered transient and don't allow to recover the result <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> in cause of
 a failure; hence, a dedicated changelog topic is required to guarantee fault-tolerance.
 <p>
 Note that this is a logical operation and only changes the "interpretation" of the stream, i.e., each record of
 it was a "fact/event" and is re-interpreted as update now (cf. <a href="KStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KStream</code></a> vs <code>KTable</code>).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> that contains the same records as this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toTable(org.apache.kafka.streams.kstream.Materialized)">
<h3>toTable</h3>
<div class="member-signature"><span class="return-type"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">toTable</span>&#8203;(<span class="parameters"><a href="Materialized.html" title="class in org.apache.kafka.streams.kstream">Materialized</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../state/KeyValueStore.html" title="interface in org.apache.kafka.streams.state">KeyValueStore</a>&lt;org.apache.kafka.common.utils.Bytes,&#8203;byte[]&gt;&gt;&nbsp;materialized)</span></div>
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 <p>
 If a key changing operator was used before this operation (e.g., <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>,
 <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a> or
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>) an internal repartitioning topic will be created in Kafka.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 For this case, all data of this stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the resulting <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> is partitioned
 correctly on its key.
 Note that you cannot enable <a href="../StreamsConfig.html#TOPOLOGY_OPTIMIZATION_CONFIG"><code>StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG</code></a> config for this case, because
 repartition topics are considered transient and don't allow to recover the result <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> in cause of
 a failure; hence, a dedicated changelog topic is required to guarantee fault-tolerance.
 <p>
 Note that this is a logical operation and only changes the "interpretation" of the stream, i.e., each record of
 it was a "fact/event" and is re-interpreted as update now (cf. <a href="KStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KStream</code></a> vs <code>KTable</code>).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>materialized</code> - an instance of <a href="Materialized.html" title="class in org.apache.kafka.streams.kstream"><code>Materialized</code></a> used to describe how the state store of the
                            resulting table should be materialized.</dd>
<dt>Returns:</dt>
<dd>a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> that contains the same records as this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toTable(org.apache.kafka.streams.kstream.Named,org.apache.kafka.streams.kstream.Materialized)">
<h3>toTable</h3>
<div class="member-signature"><span class="return-type"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">toTable</span>&#8203;(<span class="parameters"><a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="Materialized.html" title="class in org.apache.kafka.streams.kstream">Materialized</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../state/KeyValueStore.html" title="interface in org.apache.kafka.streams.state">KeyValueStore</a>&lt;org.apache.kafka.common.utils.Bytes,&#8203;byte[]&gt;&gt;&nbsp;materialized)</span></div>
<div class="block">Convert this stream to a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 <p>
 If a key changing operator was used before this operation (e.g., <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>,
 <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a> or
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>) an internal repartitioning topic will be created in Kafka.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 For this case, all data of this stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the resulting <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> is partitioned
 correctly on its key.
 Note that you cannot enable <a href="../StreamsConfig.html#TOPOLOGY_OPTIMIZATION_CONFIG"><code>StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG</code></a> config for this case, because
 repartition topics are considered transient and don't allow to recover the result <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> in cause of
 a failure; hence, a dedicated changelog topic is required to guarantee fault-tolerance.
 <p>
 Note that this is a logical operation and only changes the "interpretation" of the stream, i.e., each record of
 it was a "fact/event" and is re-interpreted as update now (cf. <a href="KStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KStream</code></a> vs <code>KTable</code>).</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>materialized</code> - an instance of <a href="Materialized.html" title="class in org.apache.kafka.streams.kstream"><code>Materialized</code></a> used to describe how the state store of the
                            resulting table should be materialized.</dd>
<dt>Returns:</dt>
<dd>a <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> that contains the same records as this <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupBy(org.apache.kafka.streams.kstream.KeyValueMapper)">
<h3>groupBy</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR&gt;</span>&nbsp;<span class="return-type"><a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">groupBy</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;KR&gt;&nbsp;keySelector)</span></div>
<div class="block">Group the records of this <code>KStream</code> on a new key that is selected using the provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a>
 and default serializers and deserializers.
 <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> can be further grouped with other streams to form a <a href="CogroupedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>CogroupedKStream</code></a>.
 Grouping a stream on the record key is required before an aggregation operator can be applied to the data
 (cf. <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>).
 The <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> selects a new key (which may or may not be of the same type) while preserving the
 original values.
 If the new record key is <code>null</code> the record will not be included in the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>
 <p>
 Because a new key is selected, an internal repartitioning topic may need to be created in Kafka if a
 later operator depends on the newly selected key.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 All data of this stream will be redistributed through the repartitioning topic by writing all records to it,
 and rereading all records from it, such that the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> is partitioned on the new key.
 <p>
 This operation is equivalent to calling <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a> followed by <a href="#groupByKey()"><code>groupByKey()</code></a>.
 If the key type is changed, it is recommended to use <a href="#groupBy(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Grouped)"><code>groupBy(KeyValueMapper, Grouped)</code></a> instead.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the key type of the result <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a></dd>
<dt>Parameters:</dt>
<dd><code>keySelector</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes a new key for grouping</dd>
<dt>Returns:</dt>
<dd>a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> that contains the grouped records of the original <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupBy(org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.Grouped)">
<h3>groupBy</h3>
<div class="member-signature"><span class="type-parameters">&lt;KR&gt;</span>&nbsp;<span class="return-type"><a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">groupBy</span>&#8203;(<span class="parameters"><a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;KR&gt;&nbsp;keySelector,
<a href="Grouped.html" title="class in org.apache.kafka.streams.kstream">Grouped</a>&lt;KR,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;grouped)</span></div>
<div class="block">Group the records of this <code>KStream</code> on a new key that is selected using the provided <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a>
 and <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>Serde</code></a>s as specified by <a href="Grouped.html" title="class in org.apache.kafka.streams.kstream"><code>Grouped</code></a>.
 <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> can be further grouped with other streams to form a <a href="CogroupedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>CogroupedKStream</code></a>.
 Grouping a stream on the record key is required before an aggregation operator can be applied to the data
 (cf. <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>).
 The <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> selects a new key (which may or may not be of the same type) while preserving the
 original values.
 If the new record key is <code>null</code> the record will not be included in the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>.
 <p>
 Because a new key is selected, an internal repartitioning topic may need to be created in Kafka if a later
 operator depends on the newly selected key.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is either provided via <a href="Grouped.html#as(java.lang.String)"><code>Grouped.as(String)</code></a> or an
 internally generated name.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 All data of this stream will be redistributed through the repartitioning topic by writing all records to it,
 and rereading all records from it, such that the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> is partitioned on the new key.
 <p>
 This operation is equivalent to calling <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a> followed by <a href="#groupByKey()"><code>groupByKey()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>KR</code> - the key type of the result <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a></dd>
<dt>Parameters:</dt>
<dd><code>keySelector</code> - a <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> that computes a new key for grouping</dd>
<dd><code>grouped</code> - the <a href="Grouped.html" title="class in org.apache.kafka.streams.kstream"><code>Grouped</code></a> instance used to specify <a href="../../common/serialization/Serdes.html" title="class in org.apache.kafka.common.serialization"><code>Serdes</code></a>
                    and part of the name for a repartition topic if repartitioning is required.</dd>
<dt>Returns:</dt>
<dd>a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> that contains the grouped records of the original <code>KStream</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey()">
<h3>groupByKey</h3>
<div class="member-signature"><span class="return-type"><a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">groupByKey</span>()</div>
<div class="block">Group the records by their current key into a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> while preserving the original values
 and default serializers and deserializers.
 <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> can be further grouped with other streams to form a <a href="CogroupedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>CogroupedKStream</code></a>.
 Grouping a stream on the record key is required before an aggregation operator can be applied to the data
 (cf. <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>).
 If a record key is <code>null</code> the record will not be included in the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>.
 <p>
 If a key changing operator was used before this operation (e.g., <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>,
 <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a> or
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>) an internal repartitioning topic may need to be created in
 Kafka if a later operator depends on the newly selected key.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "&lt;name&gt;" is an internally generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 For this case, all data of this stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> is partitioned
 correctly on its key.
 If the last key changing operator changed the key type, it is recommended to use
 <a href="#groupByKey(org.apache.kafka.streams.kstream.Grouped)"><code>groupByKey(org.apache.kafka.streams.kstream.Grouped)</code></a> instead.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> that contains the grouped records of the original <code>KStream</code></dd>
<dt>See Also:</dt>
<dd><a href="#groupBy(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>groupBy(KeyValueMapper)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey(org.apache.kafka.streams.kstream.Grouped)">
<h3>groupByKey</h3>
<div class="member-signature"><span class="return-type"><a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream">KGroupedStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;</span>&nbsp;<span class="member-name">groupByKey</span>&#8203;(<span class="parameters"><a href="Grouped.html" title="class in org.apache.kafka.streams.kstream">Grouped</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;grouped)</span></div>
<div class="block">Group the records by their current key into a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> while preserving the original values
 and using the serializers as defined by <a href="Grouped.html" title="class in org.apache.kafka.streams.kstream"><code>Grouped</code></a>.
 <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> can be further grouped with other streams to form a <a href="CogroupedKStream.html" title="interface in org.apache.kafka.streams.kstream"><code>CogroupedKStream</code></a>.
 Grouping a stream on the record key is required before an aggregation operator can be applied to the data
 (cf. <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>).
 If a record key is <code>null</code> the record will not be included in the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a>.
 <p>
 If a key changing operator was used before this operation (e.g., <a href="#selectKey(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>selectKey(KeyValueMapper)</code></a>,
 <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a> or
 <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>) an internal repartitioning topic may need to be created in
 Kafka if a later operator depends on the newly selected key.
 This topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is user-specified in
 <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 &lt;name&gt; is either provided via <a href="Grouped.html#as(java.lang.String)"><code>Grouped.as(String)</code></a> or an internally
 generated name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 For this case, all data of this stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the resulting <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>grouped</code> - the <a href="Grouped.html" title="class in org.apache.kafka.streams.kstream"><code>Grouped</code></a> instance used to specify <a href="../../common/serialization/Serdes.html" title="class in org.apache.kafka.common.serialization"><code>Serdes</code></a>
                  and part of the name for a repartition topic if repartitioning is required.</dd>
<dt>Returns:</dt>
<dd>a <a href="KGroupedStream.html" title="interface in org.apache.kafka.streams.kstream"><code>KGroupedStream</code></a> that contains the grouped records of the original <code>KStream</code></dd>
<dt>See Also:</dt>
<dd><a href="#groupBy(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>groupBy(KeyValueMapper)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join with default
 serializers and deserializers.
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoiner(B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "storeName" is an
 internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>leftJoin(KStream, ValueJoiner, JoinWindows)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>outerJoin(KStream, ValueJoiner, JoinWindows)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join with default
 serializers and deserializers.
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 The key of the result record is the same as for both joining input records.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoinerWithKey(K1,B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "storeName" is an
 internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>leftJoin(KStream, ValueJoinerWithKey, JoinWindows)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>outerJoin(KStream, ValueJoinerWithKey, JoinWindows)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoiner(B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names,
 unless a name is provided via a <code>Materialized</code> instance.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "storeName" is an
 internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dd><code>streamJoined</code> - a <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> used to configure join stores</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>leftJoin(KStream, ValueJoiner, JoinWindows, StreamJoined)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>outerJoin(KStream, ValueJoiner, JoinWindows, StreamJoined)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed inner equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 The key of the result record is the same as for both joining input records.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoinerWithKey(K1,B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names,
 unless a name is provided via a <code>Materialized</code> instance.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "storeName" is an
 internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dd><code>streamJoined</code> - a <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> used to configure join stores</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>leftJoin(KStream, ValueJoinerWithKey, JoinWindows, StreamJoined)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>outerJoin(KStream, ValueJoinerWithKey, JoinWindows, StreamJoined)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a>, all records from this stream will
 produce at least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of this <code>KStream</code> that does not satisfy the join predicate the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called with a <code>null</code> value for the other stream.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoiner(A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoiner(B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 this <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>join(KStream, ValueJoiner, JoinWindows)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>outerJoin(KStream, ValueJoiner, JoinWindows)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a>, all records from this stream will
 produce at least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of this <code>KStream</code> that does not satisfy the join predicate the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called with a <code>null</code> value for the other stream.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoinerWithKey(K1, A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoinerWithKey(K2, B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 this <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>join(KStream, ValueJoinerWithKey, JoinWindows)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>outerJoin(KStream, ValueJoinerWithKey, JoinWindows)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a>, all records from this stream will
 produce at least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of this <code>KStream</code> that does not satisfy the join predicate the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called with a <code>null</code> value for the other stream.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoiner(A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoiner(B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names,
 unless a name is provided via a <code>Materialized</code> instance.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dd><code>streamJoined</code> - a <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance to configure serdes and state stores</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 this <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>join(KStream, ValueJoiner, JoinWindows, StreamJoined)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>outerJoin(KStream, ValueJoiner, JoinWindows, StreamJoined)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed left equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a>, all records from this stream will
 produce at least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of this <code>KStream</code> that does not satisfy the join predicate the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called with a <code>null</code> value for the other stream.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoinerWithKey(K1,A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoinerWithKey(K2,B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td></td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names,
 unless a name is provided via a <code>Materialized</code> instance.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dd><code>streamJoined</code> - a <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance to configure serdes and state stores</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 this <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>join(KStream, ValueJoinerWithKey, JoinWindows, StreamJoined)</code></a>, 
<a href="#outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>outerJoin(KStream, ValueJoinerWithKey, JoinWindows, StreamJoined)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)">
<h3>outerJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">outerJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a> or
 <a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>left-join</code></a>, all records from both streams will produce at
 least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of both <code>KStream</code>s that does not satisfy the join predicate the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called with a <code>null</code> value for the this/other stream, respectively.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoiner(A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoiner(null,b)&gt;<br></br>&lt;K2:ValueJoiner(B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td>&lt;K3:ValueJoiner(null,c)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 both <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>join(KStream, ValueJoiner, JoinWindows)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>leftJoin(KStream, ValueJoiner, JoinWindows)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)">
<h3>outerJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">outerJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a> or
 <a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>left-join</code></a>, all records from both streams will produce at
 least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of both <code>KStream</code>s that does not satisfy the join predicate the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called with a <code>null</code> value for the this/other stream, respectively.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoinerWithKey(K1,A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoinerWithKey(K2,null,b)&gt;<br></br>&lt;K2:ValueJoinerWithKey(K2,B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td>&lt;K3:ValueJoinerWithKey(K3,null,c)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 both <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>join(KStream, ValueJoinerWithKey, JoinWindows)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>leftJoin(KStream, ValueJoinerWithKey, JoinWindows)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">
<h3>outerJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">outerJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a> or
 <a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows)"><code>left-join</code></a>, all records from both streams will produce at
 least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of both <code>KStream</code>s that does not satisfy the join predicate the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called with a <code>null</code> value for this/other stream, respectively.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoiner(A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoiner(null,b)&gt;<br></br>&lt;K2:ValueJoiner(B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td>&lt;K3:ValueJoiner(null,c)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names,
 unless a name is provided via a <code>Materialized</code> instance.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dd><code>streamJoined</code> - a <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance to configure serdes and state stores</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 both <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>join(KStream, ValueJoiner, JoinWindows, StreamJoined)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>leftJoin(KStream, ValueJoiner, JoinWindows, StreamJoined)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="outerJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)">
<h3>outerJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VO,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">outerJoin</span>&#8203;(<span class="parameters"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VO&gt;&nbsp;otherStream,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VO,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream">JoinWindows</a>&nbsp;windows,
<a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream">StreamJoined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VO&gt;&nbsp;streamJoined)</span></div>
<div class="block">Join records of this stream with another <code>KStream</code>'s records using windowed outer equi join using the
 <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance for configuration of the <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>key serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>this stream's value
 serde</code></a>, <a href="../../common/serialization/Serde.html" title="interface in org.apache.kafka.common.serialization"><code>the other stream's value serde</code></a>, and used state stores.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>inner-join</code></a> or
 <a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows)"><code>left-join</code></a>, all records from both streams will produce at
 least one output record (cf. below).
 The join is computed on the records' key with join attribute <code>thisKStream.key == otherKStream.key</code>.
 Furthermore, two records are only joined if their timestamps are close to each other as defined by the given
 <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a>, i.e., the window defines an additional join predicate on the record timestamps.
 <p>
 For each pair of records meeting both join predicates the provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute
 a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 The key of the result record is the same as for both joining input records.
 Furthermore, for each input record of both <code>KStream</code>s that does not satisfy the join predicate the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called with a <code>null</code> value for this/other stream, respectively.
 If an input record key or value is <code>null</code> the record will not be included in the join operation and thus no
 output record will be added to the resulting <code>KStream</code>.
 <p>
 Example (assuming all input records belong to the correct windows):
 <table border='1'>
 <tr>
 <th>this</th>
 <th>other</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td>&lt;K1:ValueJoinerWithKey(K1,A,null)&gt;</td>
 </tr>
 <tr>
 <td>&lt;K2:B&gt;</td>
 <td>&lt;K2:b&gt;</td>
 <td>&lt;K2:ValueJoinerWithKey(K2,null,b)&gt;<br></br>&lt;K2:ValueJoinerWithKey(K2,B,b)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K3:c&gt;</td>
 <td>&lt;K3:ValueJoinerWithKey(K3,null,c)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> (for one input stream) before
 doing the join and specify the "correct" number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner).
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 Repartitioning can happen for one or both of the joining <code>KStream</code>s.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.
 <p>
 Both of the joining <code>KStream</code>s will be materialized in local state stores with auto-generated store names,
 unless a name is provided via a <code>Materialized</code> instance.
 For failure and recovery each store will be backed by an internal changelog topic that will be created in Kafka.
 The changelog topic will be named "${applicationId}-&lt;storename&gt;-changelog", where "applicationId" is user-specified
 in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>,
 "storeName" is an internally generated name, and "-changelog" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VO</code> - the value type of the other stream</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>otherStream</code> - the <code>KStream</code> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>windows</code> - the specification of the <a href="JoinWindows.html" title="class in org.apache.kafka.streams.kstream"><code>JoinWindows</code></a></dd>
<dd><code>streamJoined</code> - a <a href="StreamJoined.html" title="class in org.apache.kafka.streams.kstream"><code>StreamJoined</code></a> instance to configure serdes and state stores</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key plus one for each non-matching record of
 both <code>KStream</code> and within the joining window intervals</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>join(KStream, ValueJoinerWithKey, JoinWindows, StreamJoined)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.KStream,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.JoinWindows,org.apache.kafka.streams.kstream.StreamJoined)"><code>leftJoin(KStream, ValueJoinerWithKey, JoinWindows, StreamJoined)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoiner(C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)"><code>leftJoin(KTable, ValueJoiner)</code></a>, 
<a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.

 The key of the result record is the same as for both joining input records.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoinerWithKey(K1,C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>leftJoin(KTable, ValueJoinerWithKey)</code></a>, 
<a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Joined)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoiner(C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>joined</code> - a <a href="Joined.html" title="class in org.apache.kafka.streams.kstream"><code>Joined</code></a> instance that defines the serdes to
                    be used to serialize/deserialize inputs of the joined streams</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one for each matched record-pair with the same key</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Joined)"><code>leftJoin(KTable, ValueJoiner, Joined)</code></a>, 
<a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Joined)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed inner equi join with default
 serializers and deserializers.
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as for both joining input records.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td></td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoinerWithKey(K1,C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>joined</code> - a <a href="Joined.html" title="class in org.apache.kafka.streams.kstream"><code>Joined</code></a> instance that defines the serdes to
                    be used to serialize/deserialize inputs of the joined streams</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one for each matched record-pair with the same key</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Joined)"><code>leftJoin(KTable, ValueJoinerWithKey, Joined)</code></a>, 
<a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)"><code>inner-join</code></a>, all records from this stream will produce an
 output record (cf. below).
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 If no <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> record was found during lookup, a <code>null</code> value will be provided to <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.
 The key of the result record is the same as for both joining input records.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td>&lt;K1:ValueJoiner(A,null)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoiner(C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(KTable, ValueJoiner)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>inner-join</code></a>, all records from this stream will produce an
 output record (cf. below).
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 If no <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> record was found during lookup, a <code>null</code> value will be provided to <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>.
 The key of the result record is the same as for both joining input records.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td>&lt;K1:ValueJoinerWithKey(K1,A,null)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoinerWithKey(K1,C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(KTable, ValueJoinerWithKey)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Joined)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner)"><code>inner-join</code></a>, all records from this stream will produce an
 output record (cf. below).
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 If no <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> record was found during lookup, a <code>null</code> value will be provided to <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.
 The key of the result record is the same as for both joining input records.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td>&lt;K1:ValueJoiner(A,null)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoiner(C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>joined</code> - a <a href="Joined.html" title="class in org.apache.kafka.streams.kstream"><code>Joined</code></a> instance that defines the serdes to
                be used to serialize/deserialize inputs and outputs of the joined streams</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Joined)"><code>join(KTable, ValueJoiner, Joined)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Joined)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;VT,&#8203;
VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="KTable.html" title="interface in org.apache.kafka.streams.kstream">KTable</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VT&gt;&nbsp;table,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super VT,&#8203;? extends VR&gt;&nbsp;joiner,
<a href="Joined.html" title="class in org.apache.kafka.streams.kstream">Joined</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;<a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;VT&gt;&nbsp;joined)</span></div>
<div class="block">Join records of this stream with <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>'s records using non-windowed left equi join with default
 serializers and deserializers.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>inner-join</code></a>, all records from this stream will produce an
 output record (cf. below).
 The join is a primary key table lookup join with join attribute <code>stream.key == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> (i.e., processing time) internal
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state.
 In contrast, processing <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> input records will only update the internal <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> state and
 will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 If no <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> record was found during lookup, a <code>null</code> value will be provided to <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>.
 The key of the result record is the same as for both joining input records.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 If an <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 <p>
 Example:
 <table border='1'>
 <tr>
 <th>KStream</th>
 <th>KTable</th>
 <th>state</th>
 <th>result</th>
 </tr>
 <tr>
 <td>&lt;K1:A&gt;</td>
 <td></td>
 <td></td>
 <td>&lt;K1:ValueJoinerWithKey(K1,A,null)&gt;</td>
 </tr>
 <tr>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:b&gt;</td>
 <td></td>
 </tr>
 <tr>
 <td>&lt;K1:C&gt;</td>
 <td></td>
 <td>&lt;K1:b&gt;</td>
 <td>&lt;K1:ValueJoinerWithKey(K1,C,b)&gt;</td>
 </tr>
 </table>
 Both input streams (or to be more precise, their underlying source topics) need to have the same number of
 partitions.
 If this is not the case, you would need to call <a href="#repartition(org.apache.kafka.streams.kstream.Repartitioned)"><code>repartition(Repartitioned)</code></a> for this <code>KStream</code>
 before doing the join, specifying the same number of partitions via <a href="Repartitioned.html" title="class in org.apache.kafka.streams.kstream"><code>Repartitioned</code></a> parameter as the given
 <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 Furthermore, both input streams need to be co-partitioned on the join key (i.e., use the same partitioner);
 cf. <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a>.
 If this requirement is not met, Kafka Streams will automatically repartition the data, i.e., it will create an
 internal repartitioning topic in Kafka and write and re-read the data via this topic before the actual join.
 The repartitioning topic will be named "${applicationId}-&lt;name&gt;-repartition", where "applicationId" is
 user-specified in <a href="../StreamsConfig.html" title="class in org.apache.kafka.streams"><code>StreamsConfig</code></a> via parameter
 <a href="../StreamsConfig.html#APPLICATION_ID_CONFIG"><code>APPLICATION_ID_CONFIG</code></a>, "&lt;name&gt;" is an internally generated
 name, and "-repartition" is a fixed suffix.
 <p>
 You can retrieve all generated internal topic names via <a href="../Topology.html#describe()"><code>Topology.describe()</code></a>.
 <p>
 Repartitioning can happen only for this <code>KStream</code> but not for the provided <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a>.
 For this case, all data of the stream will be redistributed through the repartitioning topic by writing all
 records to it, and rereading all records from it, such that the join input <code>KStream</code> is partitioned
 correctly on its key.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VT</code> - the value type of the table</dd>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>table</code> - the <a href="KTable.html" title="interface in org.apache.kafka.streams.kstream"><code>KTable</code></a> to be joined with this stream</dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>joined</code> - a <a href="Joined.html" title="class in org.apache.kafka.streams.kstream"><code>Joined</code></a> instance that defines the serdes to
                be used to serialize/deserialize inputs and outputs of the joined streams</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.KTable,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Joined)"><code>join(KTable, ValueJoinerWithKey, Joined)</code></a>, 
<a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as the key of this <code>KStream</code>.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, no output record will be added to the
 resulting <code>KStream</code>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as the key of this <code>KStream</code>.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, no output record will be added to the
 resulting <code>KStream</code>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Named)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the provided
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as the key of this <code>KStream</code>.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, no output record will be added to the
 resulting <code>KStream</code>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>joiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Named)">
<h3>join</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">join</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;joiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed inner equi join.
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record that finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the provided
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as the key of this <code>KStream</code>.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, no output record will be added to the
 resulting <code>KStream</code>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>joiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>leftJoin(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>inner-join</code></a>, all records from this stream
 will produce an output record (cf. below).
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the
 provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as this <code>KStream</code>.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, a <code>null</code> value will be
 provided to <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.
 If no <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> record was found during lookup, a <code>null</code> value will be provided to
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>valueJoiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>inner-join</code></a>, all records from this stream
 will produce an output record (cf. below).
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the
 provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as this <code>KStream</code>.
 Note that the key is read-only and should not be modified, as this can lead to undefined behaviour.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, a <code>null</code> value will be
 provided to <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>.
 If no <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> record was found during lookup, a <code>null</code> value will be provided to
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>valueJoiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner,org.apache.kafka.streams.kstream.Named)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream">ValueJoiner</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>inner-join</code></a>, all records from this stream
 will produce an output record (cf. below).
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the
 provided <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as this <code>KStream</code>.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, a <code>null</code> value will be
 provided to <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.
 If no <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> record was found during lookup, a <code>null</code> value will be provided to
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>valueJoiner</code> - a <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoiner.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoiner</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoiner)"><code>join(GlobalKTable, KeyValueMapper, ValueJoiner)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftJoin(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey,org.apache.kafka.streams.kstream.Named)">
<h3>leftJoin</h3>
<div class="member-signature"><span class="type-parameters">&lt;GK,&#8203;
GV,&#8203;
RV&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;RV&gt;</span>&nbsp;<span class="member-name">leftJoin</span>&#8203;(<span class="parameters"><a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream">GlobalKTable</a>&lt;GK,&#8203;GV&gt;&nbsp;globalTable,
<a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream">KeyValueMapper</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends GK&gt;&nbsp;keySelector,
<a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream">ValueJoinerWithKey</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? super GV,&#8203;? extends RV&gt;&nbsp;valueJoiner,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named)</span></div>
<div class="block">Join records of this stream with <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>'s records using non-windowed left equi join.
 In contrast to <a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>inner-join</code></a>, all records from this stream
 will produce an output record (cf. below).
 The join is a primary key table lookup join with join attribute
 <code>keyValueMapper.map(stream.keyValue) == table.key</code>.
 "Table lookup join" means, that results are only computed if <code>KStream</code> records are processed.
 This is done by performing a lookup for matching records in the <em>current</em> internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state.
 In contrast, processing <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> input records will only update the internal <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a>
 state and will not produce any result records.
 <p>
 For each <code>KStream</code> record whether or not it finds a corresponding record in <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> the
 provided <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> will be called to compute a value (with arbitrary type) for the result record.
 The key of the result record is the same as this <code>KStream</code>.
 If a <code>KStream</code> input record key or value is <code>null</code> the record will not be included in the join
 operation and thus no output record will be added to the resulting <code>KStream</code>.
 If <code>keyValueMapper</code> returns <code>null</code> implying no match exists, a <code>null</code> value will be
 provided to <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>.
 If no <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> record was found during lookup, a <code>null</code> value will be provided to
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>GK</code> - the key type of <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>GV</code> - the value type of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>RV</code> - the value type of the resulting <code>KStream</code></dd>
<dt>Parameters:</dt>
<dd><code>globalTable</code> - the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a> to be joined with this stream</dd>
<dd><code>keySelector</code> - instance of <a href="KeyValueMapper.html" title="interface in org.apache.kafka.streams.kstream"><code>KeyValueMapper</code></a> used to map from the (key, value) of this stream
                       to the key of the <a href="GlobalKTable.html" title="interface in org.apache.kafka.streams.kstream"><code>GlobalKTable</code></a></dd>
<dd><code>valueJoiner</code> - a <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a> that computes the join result for a pair of matching records</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains join-records for each key and values computed by the given
 <a href="ValueJoinerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueJoinerWithKey</code></a>, one output for each input <code>KStream</code> record</dd>
<dt>See Also:</dt>
<dd><a href="#join(org.apache.kafka.streams.kstream.GlobalKTable,org.apache.kafka.streams.kstream.KeyValueMapper,org.apache.kafka.streams.kstream.ValueJoinerWithKey)"><code>join(GlobalKTable, KeyValueMapper, ValueJoinerWithKey)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)">
<h3>transform</h3>
<div class="member-signature"><span class="type-parameters">&lt;K1,&#8203;
V1&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</span>&nbsp;<span class="member-name">transform</span>&#8203;(<span class="parameters"><a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&nbsp;transformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform each record of the input stream into zero or one record in the output stream (both key and value type
 can be altered arbitrarily).
 A <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> (provided by the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a>) is applied to each input record and
 returns zero or one output record.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K':V'&gt;</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>,
 the processing progress can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transform(new TransformerSupplier() {
     public Transformer get() {
         return new MyTransformer();
     }
 }, "myTransformState");
 </code></pre>
 The second strategy is for the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyTransformerSupplier implements TransformerSupplier {
     // supply transformer
     Transformer get() {
         return new MyTransformer();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.transform(new MyTransformerSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> must return a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> type in <a href="Transformer.html#transform(K,V)"><code>transform()</code></a>.
 The return value of <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> may be <code>null</code>,
 in which case no record is emitted.
 <pre><code>
 class MyTransformer implements Transformer {
     private ProcessorContext context;
     private StateStore state;

     void init(ProcessorContext context) {
         this.context = context;
         this.state = context.getStateStore("myTransformState");
         // punctuate each second; can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     KeyValue transform(K key, V value) {
         // can access this.state
         return new KeyValue(key, value); // can emit a single value via return -- can also be null
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before <code>transform()</code>.
 <p>
 Transforming records might result in an internal data redistribution if a key based operator (like an aggregation
 or join) is applied to the result <code>KStream</code>.
 (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues()</code></a> )
 <p>
 Note that it is possible to emit multiple records for each input record by using
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> in
 <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 Be aware that a mismatch between the types of the emitted records and the type of the stream would only be
 detected at runtime.
 To ensure type-safety at compile-time,
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> should
 not be used in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 If in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> multiple records need to be emitted
 for each input record, it is recommended to use <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>.
 The supplier should always generate a new instance each time <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> gets called. Creating
 a single <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> object and returning the same object reference in <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> would be
 a violation of the supplier pattern and leads to runtime exceptions.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>K1</code> - the key type of the new stream</dd>
<dd><code>V1</code> - the value type of the new stream</dd>
<dt>Parameters:</dt>
<dd><code>transformerSupplier</code> - an instance of <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> that generates a newly constructed
                            <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a></dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                            implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with new key and value (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transform(org.apache.kafka.streams.kstream.TransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>transform</h3>
<div class="member-signature"><span class="type-parameters">&lt;K1,&#8203;
V1&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</span>&nbsp;<span class="member-name">transform</span>&#8203;(<span class="parameters"><a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&nbsp;transformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform each record of the input stream into zero or one record in the output stream (both key and value type
 can be altered arbitrarily).
 A <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> (provided by the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a>) is applied to each input record and
 returns zero or one output record.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K':V'&gt;</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>,
 the processing progress can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transform(new TransformerSupplier() {
     public Transformer get() {
         return new MyTransformer();
     }
 }, "myTransformState");
 </code></pre>
 The second strategy is for the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyTransformerSupplier implements TransformerSupplier {
     // supply transformer
     Transformer get() {
         return new MyTransformer();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.transform(new MyTransformerSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> must return a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> type in <a href="Transformer.html#transform(K,V)"><code>transform()</code></a>.
 The return value of <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> may be <code>null</code>,
 in which case no record is emitted.
 <pre><code>
 class MyTransformer implements Transformer {
     private ProcessorContext context;
     private StateStore state;

     void init(ProcessorContext context) {
         this.context = context;
         this.state = context.getStateStore("myTransformState");
         // punctuate each second; can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     KeyValue transform(K key, V value) {
         // can access this.state
         return new KeyValue(key, value); // can emit a single value via return -- can also be null
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before <code>transform()</code>.
 <p>
 Transforming records might result in an internal data redistribution if a key based operator (like an aggregation
 or join) is applied to the result <code>KStream</code>.
 (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues()</code></a> )
 <p>
 Note that it is possible to emit multiple records for each input record by using
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> in
 <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 Be aware that a mismatch between the types of the emitted records and the type of the stream would only be
 detected at runtime.
 To ensure type-safety at compile-time,
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> should
 not be used in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 If in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> multiple records need to be emitted
 for each input record, it is recommended to use <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>.
 The supplier should always generate a new instance each time <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> gets called. Creating
 a single <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> object and returning the same object reference in <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> would be
 a violation of the supplier pattern and leads to runtime exceptions.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>K1</code> - the key type of the new stream</dd>
<dd><code>V1</code> - the value type of the new stream</dd>
<dt>Parameters:</dt>
<dd><code>transformerSupplier</code> - an instance of <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> that generates a newly constructed
                            <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a></dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                            implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with new key and value (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#map(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>map(KeyValueMapper)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)">
<h3>flatTransform</h3>
<div class="member-signature"><span class="type-parameters">&lt;K1,&#8203;
V1&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</span>&nbsp;<span class="member-name">flatTransform</span>&#8203;(<span class="parameters"><a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&gt;&nbsp;transformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).
 A <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> (provided by the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a>) is applied to each input record and
 returns zero or more output records.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K':V'&gt;, &lt;K'':V''&gt;, ...</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>
 the processing progress can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transform(new TransformerSupplier() {
     public Transformer get() {
         return new MyTransformer();
     }
 }, "myTransformState");
 </code></pre>
 The second strategy is for the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyTransformerSupplier implements TransformerSupplier {
     // supply transformer
     Transformer get() {
         return new MyTransformer();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.flatTransform(new MyTransformerSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> type (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a>
 type) in <a href="Transformer.html#transform(K,V)"><code>transform()</code></a>.
 The return value of <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> may be <code>null</code>,
 which is equal to returning an empty <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a>, i.e., no records are emitted.
 <pre><code>
 class MyTransformer implements Transformer {
     private ProcessorContext context;
     private StateStore state;

     void init(ProcessorContext context) {
         this.context = context;
         this.state = context.getStateStore("myTransformState");
         // punctuate each second; can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     Iterable&lt;KeyValue&gt; transform(K key, V value) {
         // can access this.state
         List&lt;KeyValue&gt; result = new ArrayList&lt;&gt;();
         for (int i = 0; i &lt; 3; i++) {
             result.add(new KeyValue(key, value));
         }
         return result; // emits a list of key-value pairs via return
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>flatTransform()</code>.
 <p>
 Transforming records might result in an internal data redistribution if a key based operator (like an aggregation
 or join) is applied to the result <code>KStream</code>.
 (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues()</code></a>)
 <p>
 Note that it is possible to emit records by using
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 Be aware that a mismatch between the types of the emitted records and the type of the stream would only be
 detected at runtime.
 To ensure type-safety at compile-time,
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> should
 not be used in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 The supplier should always generate a new instance each time <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> gets called. Creating
 a single <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> object and returning the same object reference in <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> would be
 a violation of the supplier pattern and leads to runtime exceptions.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>K1</code> - the key type of the new stream</dd>
<dd><code>V1</code> - the value type of the new stream</dd>
<dt>Parameters:</dt>
<dd><code>transformerSupplier</code> - an instance of <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> that generates a newly constructed <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a></dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                            implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with new key and value (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>flatTransform</h3>
<div class="member-signature"><span class="type-parameters">&lt;K1,&#8203;
V1&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;K1,&#8203;V1&gt;</span>&nbsp;<span class="member-name">flatTransform</span>&#8203;(<span class="parameters"><a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">TransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;<a href="../KeyValue.html" title="class in org.apache.kafka.streams">KeyValue</a>&lt;K1,&#8203;V1&gt;&gt;&gt;&nbsp;transformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform each record of the input stream into zero or more records in the output stream (both key and value type
 can be altered arbitrarily).
 A <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> (provided by the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a>) is applied to each input record and
 returns zero or more output records.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K':V'&gt;, &lt;K'':V''&gt;, ...</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>
 the processing progress can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transform(new TransformerSupplier() {
     public Transformer get() {
         return new MyTransformer();
     }
 }, "myTransformState");
 </code></pre>
 The second strategy is for the given <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyTransformerSupplier implements TransformerSupplier {
     // supply transformer
     Transformer get() {
         return new MyTransformer();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.flatTransform(new MyTransformerSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> type (e.g., any <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a>
 type) in <a href="Transformer.html#transform(K,V)"><code>transform()</code></a>.
 The return value of <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> may be <code>null</code>,
 which is equal to returning an empty <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a>, i.e., no records are emitted.
 <pre><code>
 class MyTransformer implements Transformer {
     private ProcessorContext context;
     private StateStore state;

     void init(ProcessorContext context) {
         this.context = context;
         this.state = context.getStateStore("myTransformState");
         // punctuate each second; can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     Iterable&lt;KeyValue&gt; transform(K key, V value) {
         // can access this.state
         List&lt;KeyValue&gt; result = new ArrayList&lt;&gt;();
         for (int i = 0; i &lt; 3; i++) {
             result.add(new KeyValue(key, value));
         }
         return result; // emits a list of key-value pairs via return
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>flatTransform()</code>.
 <p>
 Transforming records might result in an internal data redistribution if a key based operator (like an aggregation
 or join) is applied to the result <code>KStream</code>.
 (cf. <a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues()</code></a>)
 <p>
 Note that it is possible to emit records by using
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 Be aware that a mismatch between the types of the emitted records and the type of the stream would only be
 detected at runtime.
 To ensure type-safety at compile-time,
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>context#forward()</code></a> should
 not be used in <a href="Transformer.html#transform(K,V)"><code>Transformer#transform()</code></a> and
 <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>.
 The supplier should always generate a new instance each time <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> gets called. Creating
 a single <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a> object and returning the same object reference in <a href="TransformerSupplier.html#get()"><code>TransformerSupplier.get()</code></a> would be
 a violation of the supplier pattern and leads to runtime exceptions.</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>K1</code> - the key type of the new stream</dd>
<dd><code>V1</code> - the value type of the new stream</dd>
<dt>Parameters:</dt>
<dd><code>transformerSupplier</code> - an instance of <a href="TransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>TransformerSupplier</code></a> that generates a newly constructed <a href="Transformer.html" title="interface in org.apache.kafka.streams.kstream"><code>Transformer</code></a></dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                            implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with new key and value (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#flatMap(org.apache.kafka.streams.kstream.KeyValueMapper)"><code>flatMap(KeyValueMapper)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)"><code>transformValues(ValueTransformerSupplier, String...)</code></a>, 
<a href="#transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)"><code>transformValues(ValueTransformerWithKeySupplier, String...)</code></a>, 
<a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(ProcessorSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)">
<h3>transformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">transformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.
 A <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> (provided by the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a>) is applied to each input
 record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transformValues(new ValueTransformerSupplier() {
     public ValueTransformer get() {
         return new MyValueTransformer();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerSupplier implements ValueTransformerSupplier {
     // supply transformer
     ValueTransformer get() {
         return new MyValueTransformer();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.transformValues(new MyValueTransformerSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> must return the new value in <a href="ValueTransformer.html#transform(V)"><code>transform()</code></a>.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a>
 pairs can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> tries to
 emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformer implements ValueTransformer {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     NewValueType transform(V value) {
         // can access this.state
         return new NewValueType(); // or null
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>transformValues()</code>.
 <p>
 Setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> that generates a newly constructed <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> object
                                 and returning the same object reference in <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>transformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">transformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.
 A <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> (provided by the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a>) is applied to each input
 record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transformValues(new ValueTransformerSupplier() {
     public ValueTransformer get() {
         return new MyValueTransformer();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerSupplier implements ValueTransformerSupplier {
     // supply transformer
     ValueTransformer get() {
         return new MyValueTransformer();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.transformValues(new MyValueTransformerSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> must return the new value in <a href="ValueTransformer.html#transform(V)"><code>transform()</code></a>.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a>
 pairs can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> tries to
 emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformer implements ValueTransformer {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     NewValueType transform(V value) {
         // can access this.state
         return new NewValueType(); // or null
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>transformValues()</code>.
 <p>
 Setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> that generates a newly constructed <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> object
                                 and returning the same object reference in <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)">
<h3>transformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">transformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.
 A <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> (provided by the given <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a>) is applied to
 each input record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transformValues(new ValueTransformerWithKeySupplier() {
     public ValueTransformer get() {
         return new MyValueTransformer();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerWithKeySupplier implements ValueTransformerWithKeySupplier {
     // supply transformer
     ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.transformValues(new MyValueTransformerWithKeySupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> must return the new value in
 <a href="ValueTransformerWithKey.html#transform(K,V)"><code>transform()</code></a>.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a> and
 <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs
 can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> tries
 to emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformerWithKey implements ValueTransformerWithKey {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     NewValueType transform(K readOnlyKey, V value) {
         // can access this.state and use read-only key
         return new NewValueType(readOnlyKey); // or null
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>transformValues()</code>.
 <p>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a> that generates a newly constructed <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> object
                                 and returning the same object reference in <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>transformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">transformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;? extends VR&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into a new value (with possibly a new type) of the output record.
 A <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> (provided by the given <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a>) is applied to
 each input record value and computes a new value for it.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into an output record <code>&lt;K:V'&gt;</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.transformValues(new ValueTransformerWithKeySupplier() {
     public ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerWithKeySupplier implements ValueTransformerWithKeySupplier {
     // supply transformer
     ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.transformValues(new MyValueTransformerWithKeySupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> must return the new value in
 <a href="ValueTransformerWithKey.html#transform(K,V)"><code>transform()</code></a>.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a> and
 <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs
 can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> tries
 to emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformerWithKey implements ValueTransformerWithKey {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     NewValueType transform(K readOnlyKey, V value) {
         // can access this.state and use read-only key
         return new NewValueType(readOnlyKey); // or null
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>transformValues()</code>.
 <p>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a> that generates a newly constructed <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> object
                                 and returning the same object reference in <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains records with unmodified key and new values (possibly of different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,java.lang.String...)">
<h3>flatTransformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatTransformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.
 A <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> (provided by the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a>) is applied to each input
 record value and computes zero or more new values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>
 the processing progress can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.flatTransformValues(new ValueTransformerSupplier() {
     public ValueTransformer get() {
         return new MyValueTransformer();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerSupplier implements ValueTransformerSupplier {
     // supply transformer
     ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.flatTransformValues(new MyValueTransformer());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> type (e.g., any
 <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type) in <a href="ValueTransformer.html#transform(V)"><code>transform()</code></a>.
 If the return value of <a href="ValueTransformer.html#transform(V)"><code>ValueTransformer#transform()</code></a> is an empty
 <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> or <code>null</code>, no records are emitted.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a> and
 <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs
 can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> tries to
 emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformer implements ValueTransformer {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     Iterable&lt;NewValueType&gt; transform(V value) {
         // can access this.state
         List&lt;NewValueType&gt; result = new ArrayList&lt;&gt;();
         for (int i = 0; i &lt; 3; i++) {
             result.add(new NewValueType(value));
         }
         return result; // values
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>flatTransformValues()</code>.
 <p>
 Setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> that generates a newly constructed <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> object
                                 and returning the same object reference in <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified key and new values (possibly of
 different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>flatTransformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatTransformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.
 A <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> (provided by the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a>) is applied to each input
 record value and computes zero or more new values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator#punctuate()</code></a>
 the processing progress can be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.flatTransformValues(new ValueTransformerSupplier() {
     public ValueTransformer get() {
         return new MyValueTransformer();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerSupplier implements ValueTransformerSupplier {
     // supply transformer
     ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.flatTransformValues(new MyValueTransformer());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> type (e.g., any
 <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type) in <a href="ValueTransformer.html#transform(V)"><code>transform()</code></a>.
 If the return value of <a href="ValueTransformer.html#transform(V)"><code>ValueTransformer#transform()</code></a> is an empty
 <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> or <code>null</code>, no records are emitted.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a> and
 <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs
 can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> tries to
 emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformer implements ValueTransformer {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     Iterable&lt;NewValueType&gt; transform(V value) {
         // can access this.state
         List&lt;NewValueType&gt; result = new ArrayList&lt;&gt;();
         for (int i = 0; i &lt; 3; i++) {
             result.add(new NewValueType(value));
         }
         return result; // values
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>flatTransformValues()</code>.
 <p>
 Setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> that generates a newly constructed <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> object
                                 and returning the same object reference in <a href="ValueTransformer.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformer</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified key and new values (possibly of
 different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,java.lang.String...)">
<h3>flatTransformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatTransformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.
 A <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> (provided by the given <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a>) is applied to
 each input record value and computes zero or more new values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress can
 be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.flatTransformValues(new ValueTransformerWithKeySupplier() {
     public ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerWithKeySupplier implements ValueTransformerWithKeySupplier {
     // supply transformer
     ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.flatTransformValues(new MyValueTransformerWithKey());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> type (e.g., any
 <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type) in <a href="ValueTransformerWithKey.html#transform(K,V)"><code>transform()</code></a>.
 If the return value of <a href="ValueTransformerWithKey.html#transform(K,V)"><code>ValueTransformerWithKey#transform()</code></a>
 is an empty <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> or <code>null</code>, no records are emitted.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a> and
 <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs
 can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> tries
 to emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformerWithKey implements ValueTransformerWithKey {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     Iterable&lt;NewValueType&gt; transform(K readOnlyKey, V value) {
         // can access this.state and use read-only key
         List&lt;NewValueType&gt; result = new ArrayList&lt;&gt;();
         for (int i = 0; i &lt; 3; i++) {
             result.add(new NewValueType(readOnlyKey));
         }
         return result; // values
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>flatTransformValues()</code>.
 <p>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a> that generates a newly constructed <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> object
                                 and returning the same object reference in <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified key and new values (possibly of
 different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatTransformValues(org.apache.kafka.streams.kstream.ValueTransformerWithKeySupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>flatTransformValues</h3>
<div class="member-signature"><span class="type-parameters">&lt;VR&gt;</span>&nbsp;<span class="return-type"><a href="KStream.html" title="interface in org.apache.kafka.streams.kstream">KStream</a>&lt;<a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;VR&gt;</span>&nbsp;<span class="member-name">flatTransformValues</span>&#8203;(<span class="parameters"><a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream">ValueTransformerWithKeySupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link">Iterable</a>&lt;VR&gt;&gt;&nbsp;valueTransformerSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Transform the value of each input record into zero or more new values (with possibly a new
 type) and emit for each new value a record with the same key of the input record and the value.
 A <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> (provided by the given <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a>) is applied to
 each input record value and computes zero or more new values.
 Thus, an input record <code>&lt;K,V&gt;</code> can be transformed into output records <code>&lt;K:V'&gt;, &lt;K:V''&gt;, ...</code>.
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues()</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#flatMapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>flatMapValues()</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress can
 be observed and additional periodic actions can be performed.
 <p>
 In order for the transformer to use state stores, the stores must be added to the topology and connected to the
 transformer using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the transformer.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.flatTransformValues(new ValueTransformerWithKeySupplier() {
     public ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }
 }, "myValueTransformState");
 </code></pre>
 The second strategy is for the given <a href="ValueTransformerSupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the transformer.
 <pre><code>
 class MyValueTransformerWithKeySupplier implements ValueTransformerWithKeySupplier {
     // supply transformer
     ValueTransformerWithKey get() {
         return new MyValueTransformerWithKey();
     }

     // provide store(s) that will be added and connected to the associated transformer
     // the store name from the builder ("myValueTransformState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myValueTransformState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.flatTransformValues(new MyValueTransformerWithKey());
 </code></pre>
 <p>
 With either strategy, within the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 The <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> must return an <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> type (e.g., any
 <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/util/Collection.html" title="class or interface in java.util" class="external-link"><code>Collection</code></a> type) in <a href="ValueTransformerWithKey.html#transform(K,V)"><code>transform()</code></a>.
 If the return value of <a href="ValueTransformerWithKey.html#transform(K,V)"><code>ValueTransformerWithKey#transform()</code></a>
 is an empty <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Iterable.html" title="class or interface in java.lang" class="external-link"><code>Iterable</code></a> or <code>null</code>, no records are emitted.
 In contrast to <a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform()</code></a> and
 <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>, no additional <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pairs
 can be emitted via
 <a href="../processor/ProcessorContext.html#forward(K,V)"><code>ProcessorContext.forward()</code></a>.
 A <a href="../errors/StreamsException.html" title="class in org.apache.kafka.streams.errors"><code>StreamsException</code></a> is thrown if the <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> tries
 to emit a <a href="../KeyValue.html" title="class in org.apache.kafka.streams"><code>KeyValue</code></a> pair.
 <pre><code>
 class MyValueTransformerWithKey implements ValueTransformerWithKey {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myValueTransformState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     Iterable&lt;NewValueType&gt; transform(K readOnlyKey, V value) {
         // can access this.state and use read-only key
         List&lt;NewValueType&gt; result = new ArrayList&lt;&gt;();
         for (int i = 0; i &lt; 3; i++) {
             result.add(new NewValueType(readOnlyKey));
         }
         return result; // values
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before
 <code>flatTransformValues()</code>.
 <p>
 Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning.
 So, setting a new value preserves data co-location with respect to the key.
 Thus, <em>no</em> internal data redistribution is required if a key based operator (like an aggregation or join)
 is applied to the result <code>KStream</code>. (cf. <a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform()</code></a>)</div>
<dl class="notes">
<dt>Type Parameters:</dt>
<dd><code>VR</code> - the value type of the result stream</dd>
<dt>Parameters:</dt>
<dd><code>valueTransformerSupplier</code> - an instance of <a href="ValueTransformerWithKeySupplier.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKeySupplier</code></a> that generates a newly constructed <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a>
                                 The supplier should always generate a new instance. Creating a single <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> object
                                 and returning the same object reference in <a href="ValueTransformerWithKey.html" title="interface in org.apache.kafka.streams.kstream"><code>ValueTransformerWithKey</code></a> is a
                                 violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                                 implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>Returns:</dt>
<dd>a <code>KStream</code> that contains more or less records with unmodified key and new values (possibly of
 different type)</dd>
<dt>See Also:</dt>
<dd><a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapper)"><code>mapValues(ValueMapper)</code></a>, 
<a href="#mapValues(org.apache.kafka.streams.kstream.ValueMapperWithKey)"><code>mapValues(ValueMapperWithKey)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a>, 
<a href="#flatTransform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>flatTransform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="process(org.apache.kafka.streams.processor.ProcessorSupplier,java.lang.String...)">
<h3>process</h3>
<div class="member-signature"><span class="annotations"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Deprecated.html" title="class or interface in java.lang" class="external-link">@Deprecated</a>
</span><span class="return-type">void</span>&nbsp;<span class="member-name">process</span>&#8203;(<span class="parameters"><a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;processorSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">Since 3.0. Use <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)"><code>process(org.apache.kafka.streams.processor.api.ProcessorSupplier, java.lang.String...)</code></a> instead.</div>
</div>
<div class="block">Process all records in this stream, one record at a time, by applying a
 <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a> (provided by the given
 <a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorSupplier</code></a>).
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 Note that this is a terminal operation that returns void.
 <p>
 In order for the processor to use state stores, the stores must be added to the topology and connected to the
 processor using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the processor.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.processor(new ProcessorSupplier() {
     public Processor get() {
         return new MyProcessor();
     }
 }, "myProcessorState");
 </code></pre>
 The second strategy is for the given <a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorSupplier</code></a>
 to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the processor.
 <pre><code>
 class MyProcessorSupplier implements ProcessorSupplier {
     // supply processor
     Processor get() {
         return new MyProcessor();
     }

     // provide store(s) that will be added and connected to the associated processor
     // the store name from the builder ("myProcessorState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.process(new MyProcessorSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a>,
 the state is obtained via the <a href="../processor/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 <pre><code>
 class MyProcessor implements Processor {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myProcessorState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     void process(K key, V value) {
         // can access this.state
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before <code>process()</code>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>processorSupplier</code> - an instance of <a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorSupplier</code></a>
                          that generates a newly constructed <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a>
                          The supplier should always generate a new instance. Creating a single
                          <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a> object
                          and returning the same object reference in
                          <a href="../processor/ProcessorSupplier.html#get()"><code>ProcessorSupplier.get()</code></a> is a
                          violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                            implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>See Also:</dt>
<dd><a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="process(org.apache.kafka.streams.processor.api.ProcessorSupplier,java.lang.String...)">
<h3>process</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">process</span>&#8203;(<span class="parameters"><a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>&gt;&nbsp;processorSupplier,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Process all records in this stream, one record at a time, by applying a <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a> (provided by the given
 <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a>).
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 Note that this is a terminal operation that returns void.
 <p>
 In order for the processor to use state stores, the stores must be added to the topology and connected to the
 processor using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the processor.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.processor(new ProcessorSupplier() {
     public Processor get() {
         return new MyProcessor();
     }
 }, "myProcessorState");
 </code></pre>
 The second strategy is for the given <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the processor.
 <pre><code>
 class MyProcessorSupplier implements ProcessorSupplier {
     // supply processor
     Processor get() {
         return new MyProcessor();
     }

     // provide store(s) that will be added and connected to the associated processor
     // the store name from the builder ("myProcessorState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.process(new MyProcessorSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 <pre><code>
 class MyProcessor implements Processor {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myProcessorState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     void process(K key, V value) {
         // can access this.state
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before <code>process()</code>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>processorSupplier</code> - an instance of <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a> that generates a newly constructed <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a>
                          The supplier should always generate a new instance. Creating a single <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a> object
                          and returning the same object reference in <a href="../processor/api/ProcessorSupplier.html#get()"><code>ProcessorSupplier.get()</code></a> is a
                          violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>stateStoreNames</code> - the names of the state stores used by the processor; not required if the supplier
                            implements <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a></dd>
<dt>See Also:</dt>
<dd><a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="process(org.apache.kafka.streams.processor.ProcessorSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>process</h3>
<div class="member-signature"><span class="annotations"><a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Deprecated.html" title="class or interface in java.lang" class="external-link">@Deprecated</a>
</span><span class="return-type">void</span>&nbsp;<span class="member-name">process</span>&#8203;(<span class="parameters"><a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>&gt;&nbsp;processorSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">Since 3.0. Use <a href="#process(org.apache.kafka.streams.processor.api.ProcessorSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)"><code>process(org.apache.kafka.streams.processor.api.ProcessorSupplier, org.apache.kafka.streams.kstream.Named, java.lang.String...)</code></a> instead.</div>
</div>
<div class="block">Process all records in this stream, one record at a time, by applying a
 <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a> (provided by the given
 <a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorSupplier</code></a>).
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 Note that this is a terminal operation that returns void.
 <p>
 In order for the processor to use state stores, the stores must be added to the topology and connected to the
 processor using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the processor.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.processor(new ProcessorSupplier() {
     public Processor get() {
         return new MyProcessor();
     }
 }, "myProcessorState");
 </code></pre>
 The second strategy is for the given <a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorSupplier</code></a>
 to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the processor.
 <pre><code>
 class MyProcessorSupplier implements ProcessorSupplier {
     // supply processor
     Processor get() {
         return new MyProcessor();
     }

     // provide store(s) that will be added and connected to the associated processor
     // the store name from the builder ("myProcessorState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.process(new MyProcessorSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a>,
 the state is obtained via the <a href="../processor/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 <pre><code>
 class MyProcessor implements Processor {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myProcessorState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     void process(K key, V value) {
         // can access this.state
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before <code>process()</code>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>processorSupplier</code> - an instance of <a href="../processor/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor"><code>ProcessorSupplier</code></a>
                          that generates a newly constructed <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a>
                          The supplier should always generate a new instance. Creating a single
                          <a href="../processor/Processor.html" title="interface in org.apache.kafka.streams.processor"><code>Processor</code></a> object
                          and returning the same object reference in
                          <a href="../processor/ProcessorSupplier.html#get()"><code>ProcessorSupplier.get()</code></a> is a
                          violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state store used by the processor</dd>
<dt>See Also:</dt>
<dd><a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="process(org.apache.kafka.streams.processor.api.ProcessorSupplier,org.apache.kafka.streams.kstream.Named,java.lang.String...)">
<h3>process</h3>
<div class="member-signature"><span class="return-type">void</span>&nbsp;<span class="member-name">process</span>&#8203;(<span class="parameters"><a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api">ProcessorSupplier</a>&lt;? super <a href="KStream.html" title="type parameter in KStream">K</a>,&#8203;? super <a href="KStream.html" title="type parameter in KStream">V</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>,&#8203;<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/Void.html" title="class or interface in java.lang" class="external-link">Void</a>&gt;&nbsp;processorSupplier,
<a href="Named.html" title="class in org.apache.kafka.streams.kstream">Named</a>&nbsp;named,
<a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;stateStoreNames)</span></div>
<div class="block">Process all records in this stream, one record at a time, by applying a <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a> (provided by the given
 <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a>).
 Attaching a state store makes this a stateful record-by-record operation (cf. <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>).
 If you choose not to attach one, this operation is similar to the stateless <a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>
 but allows access to the <code>ProcessorContext</code> and record metadata.
 This is essentially mixing the Processor API into the DSL, and provides all the functionality of the PAPI.
 Furthermore, via <a href="../processor/Punctuator.html#punctuate(long)"><code>Punctuator.punctuate(long)</code></a> the processing progress
 can be observed and additional periodic actions can be performed.
 Note that this is a terminal operation that returns void.
 <p>
 In order for the processor to use state stores, the stores must be added to the topology and connected to the
 processor using at least one of two strategies (though it's not required to connect global state stores; read-only
 access to global state stores is available by default).
 <p>
 The first strategy is to manually add the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s via <a href="../Topology.html#addStateStore(org.apache.kafka.streams.state.StoreBuilder,java.lang.String...)"><code>Topology.addStateStore(StoreBuilder, String...)</code></a>,
 and specify the store names via <code>stateStoreNames</code> so they will be connected to the processor.
 <pre><code>
 // create store
 StoreBuilder&lt;KeyValueStore&lt;String,String&gt;&gt; keyValueStoreBuilder =
         Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                 Serdes.String(),
                 Serdes.String());
 // add store
 builder.addStateStore(keyValueStoreBuilder);

 KStream outputStream = inputStream.processor(new ProcessorSupplier() {
     public Processor get() {
         return new MyProcessor();
     }
 }, "myProcessorState");
 </code></pre>
 The second strategy is for the given <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a> to implement <a href="../processor/ConnectedStoreProvider.html#stores()"><code>ConnectedStoreProvider.stores()</code></a>,
 which provides the <a href="../state/StoreBuilder.html" title="interface in org.apache.kafka.streams.state"><code>StoreBuilder</code></a>s to be automatically added to the topology and connected to the processor.
 <pre><code>
 class MyProcessorSupplier implements ProcessorSupplier {
     // supply processor
     Processor get() {
         return new MyProcessor();
     }

     // provide store(s) that will be added and connected to the associated processor
     // the store name from the builder ("myProcessorState") is used to access the store later via the ProcessorContext
     Set&lt;StoreBuilder&gt; stores() {
         StoreBuilder&lt;KeyValueStore&lt;String, String&gt;&gt; keyValueStoreBuilder =
                   Stores.keyValueStoreBuilder(Stores.persistentKeyValueStore("myProcessorState"),
                   Serdes.String(),
                   Serdes.String());
         return Collections.singleton(keyValueStoreBuilder);
     }
 }

 ...

 KStream outputStream = inputStream.process(new MyProcessorSupplier());
 </code></pre>
 <p>
 With either strategy, within the <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a>, the state is obtained via the <a href="../processor/api/ProcessorContext.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorContext</code></a>.
 To trigger periodic actions via <a href="../processor/Punctuator.html#punctuate(long)"><code>punctuate()</code></a>,
 a schedule must be registered.
 <pre><code>
 class MyProcessor implements Processor {
     private StateStore state;

     void init(ProcessorContext context) {
         this.state = context.getStateStore("myProcessorState");
         // punctuate each second, can access this.state
         context.schedule(Duration.ofSeconds(1), PunctuationType.WALL_CLOCK_TIME, new Punctuator(..));
     }

     void process(K key, V value) {
         // can access this.state
     }

     void close() {
         // can access this.state
     }
 }
 </code></pre>
 Even if any upstream operation was key-changing, no auto-repartition is triggered.
 If repartitioning is required, a call to <a href="#repartition()"><code>repartition()</code></a> should be performed before <code>process()</code>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>processorSupplier</code> - an instance of <a href="../processor/api/ProcessorSupplier.html" title="interface in org.apache.kafka.streams.processor.api"><code>ProcessorSupplier</code></a> that generates a newly constructed <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a>
                          The supplier should always generate a new instance. Creating a single <a href="../processor/api/Processor.html" title="interface in org.apache.kafka.streams.processor.api"><code>Processor</code></a> object
                          and returning the same object reference in <a href="../processor/api/ProcessorSupplier.html#get()"><code>ProcessorSupplier.get()</code></a> is a
                          violation of the supplier pattern and leads to runtime exceptions.</dd>
<dd><code>named</code> - a <a href="Named.html" title="class in org.apache.kafka.streams.kstream"><code>Named</code></a> config used to name the processor in the topology</dd>
<dd><code>stateStoreNames</code> - the names of the state store used by the processor</dd>
<dt>See Also:</dt>
<dd><a href="#foreach(org.apache.kafka.streams.kstream.ForeachAction)"><code>foreach(ForeachAction)</code></a>, 
<a href="#transform(org.apache.kafka.streams.kstream.TransformerSupplier,java.lang.String...)"><code>transform(TransformerSupplier, String...)</code></a></dd>
</dl>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
<footer role="contentinfo">
<nav role="navigation">
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottom-nav" id="navbar.bottom">
<div class="skip-nav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar.bottom.firstrow" class="nav-list" title="Navigation">
<li><a href="../../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
</div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<span class="skip-nav" id="skip.navbar.bottom">
<!--   -->
</span></nav>
</footer>
</div>
</div>
</body>
</html>
