<table class="data-table"><tbody>
<tr>
<th>Name</th>
<th>Description</th>
<th>Type</th>
<th>Default</th>
<th>Valid Values</th>
<th>Importance</th>
</tr>
<tr>
<td>name</td></td><td>Globally unique name to use for this connector.</td></td><td>string</td></td><td></td></td><td>non-empty string without ISO control characters</td></td><td>high</td></td></tr>
<tr>
<td>connector.class</td></td><td>Name or alias of the class for this connector. Must be a subclass of org.apache.kafka.connect.connector.Connector. If the connector is org.apache.kafka.connect.file.FileStreamSinkConnector, you can either specify this full name,  or use "FileStreamSink" or "FileStreamSinkConnector" to make the configuration a bit shorter</td></td><td>string</td></td><td></td></td><td></td></td><td>high</td></td></tr>
<tr>
<td>tasks.max</td></td><td>Maximum number of tasks to use for this connector.</td></td><td>int</td></td><td>1</td></td><td>[1,...]</td></td><td>high</td></td></tr>
<tr>
<td>topics</td></td><td>List of topics to consume, separated by commas</td></td><td>list</td></td><td>""</td></td><td></td></td><td>high</td></td></tr>
<tr>
<td>topics.regex</td></td><td>Regular expression giving topics to consume. Under the hood, the regex is compiled to a <code>java.util.regex.Pattern</code>. Only one of topics or topics.regex should be specified.</td></td><td>string</td></td><td>""</td></td><td>valid regex</td></td><td>high</td></td></tr>
<tr>
<td>key.converter</td></td><td>Converter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the keys in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro.</td></td><td>class</td></td><td>null</td></td><td></td></td><td>low</td></td></tr>
<tr>
<td>value.converter</td></td><td>Converter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the values in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro.</td></td><td>class</td></td><td>null</td></td><td></td></td><td>low</td></td></tr>
<tr>
<td>header.converter</td></td><td>HeaderConverter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the header values in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro. By default, the SimpleHeaderConverter is used to serialize header values to strings and deserialize them by inferring the schemas.</td></td><td>class</td></td><td>null</td></td><td></td></td><td>low</td></td></tr>
<tr>
<td>config.action.reload</td></td><td>The action that Connect should take on the connector when changes in external configuration providers result in a change in the connector's configuration properties. A value of 'none' indicates that Connect will do nothing. A value of 'restart' indicates that Connect should restart/reload the connector with the updated configuration properties.The restart may actually be scheduled in the future if the external configuration provider indicates that a configuration value will expire in the future.</td></td><td>string</td></td><td>restart</td></td><td>[none, restart]</td></td><td>low</td></td></tr>
<tr>
<td>transforms</td></td><td>Aliases for the transformations to be applied to records.</td></td><td>list</td></td><td>""</td></td><td>non-null string, unique transformation aliases</td></td><td>low</td></td></tr>
<tr>
<td>errors.retry.timeout</td></td><td>The maximum duration in milliseconds that a failed operation will be reattempted. The default is 0, which means no retries will be attempted. Use -1 for infinite retries.</td></td><td>long</td></td><td>0</td></td><td></td></td><td>medium</td></td></tr>
<tr>
<td>errors.retry.delay.max.ms</td></td><td>The maximum duration in milliseconds between consecutive retry attempts. Jitter will be added to the delay once this limit is reached to prevent thundering herd issues.</td></td><td>long</td></td><td>60000</td></td><td></td></td><td>medium</td></td></tr>
<tr>
<td>errors.tolerance</td></td><td>Behavior for tolerating errors during connector operation. 'none' is the default value and signals that any error will result in an immediate connector task failure; 'all' changes the behavior to skip over problematic records.</td></td><td>string</td></td><td>none</td></td><td>[none, all]</td></td><td>medium</td></td></tr>
<tr>
<td>errors.log.enable</td></td><td>If true, write each error and the details of the failed operation and problematic record to the Connect application log. This is 'false' by default, so that only errors that are not tolerated are reported.</td></td><td>boolean</td></td><td>false</td></td><td></td></td><td>medium</td></td></tr>
<tr>
<td>errors.log.include.messages</td></td><td>Whether to the include in the log the Connect record that resulted in a failure. This is 'false' by default, which will prevent record keys, values, and headers from being written to log files, although some information such as topic and partition number will still be logged.</td></td><td>boolean</td></td><td>false</td></td><td></td></td><td>medium</td></td></tr>
<tr>
<td>errors.deadletterqueue.topic.name</td></td><td>The name of the topic to be used as the dead letter queue (DLQ) for messages that result in an error when processed by this sink connector, or its transformations or converters. The topic name is blank by default, which means that no messages are to be recorded in the DLQ.</td></td><td>string</td></td><td>""</td></td><td></td></td><td>medium</td></td></tr>
<tr>
<td>errors.deadletterqueue.topic.replication.factor</td></td><td>Replication factor used to create the dead letter queue topic when it doesn't already exist.</td></td><td>short</td></td><td>3</td></td><td></td></td><td>medium</td></td></tr>
<tr>
<td>errors.deadletterqueue.context.headers.enable</td></td><td>If true, add headers containing error context to the messages written to the dead letter queue. To avoid clashing with headers from the original record, all error context header keys, all error context header keys will start with <code>__connect.errors.</code></td></td><td>boolean</td></td><td>false</td></td><td></td></td><td>medium</td></td></tr>
</tbody></table>
